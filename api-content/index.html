{"posts":[{"title":"Linux 离线安装应用","content":"Linux安装应用 包安装 国内常用源库 以下为国内常用源，可根据区域不同自行选择速度最快的源。若是在线安装，可参照网站指南配置，这里就不赘述了。 阿里云官方镜像站 腾讯云软件源 华为开源镜像站 网易开源镜像站 华中科技大学开源镜像站 浙江大学开源镜像站 清华大学开源软件镜像站 重庆大学开源软件镜像站 常用软件管理机制 DPKG Debian类发行版包管理，格式为xxx.deb RPM Cento类发行版包管理，格式为xxx.rpm SRPM Centos类发行版未编译包，格式为xxx.src.rpm APT Debian类发行版在线包管理 YUM Centos类发行版在线包管理 Snap Ubuntu应用包管理 Opkg Opensource嵌入式包管理，常见为Openwrt路由系统软件包工具，格式为xxx.ipk DNF Fedora类发行版在线包管理 Pacman Archlinux类发行版在线包管理 常见软件源CPU架构 各类发行版的CPU架构不同，可基本按照大类根据服务器的CPU去软件源路径目录进入。 注：noarch代表没有硬件等级上的限制，不缺分服务器系统都可安装，但存在部分依赖包关联不到的问题。 ARM系处理器：arm64、aarch64、armv6h、armv7h、armhf 、armel X86系处理器：i386、i586、i686、amd64 、x86_64 MIPS处理器：mips64el、mips、mips64e、mipsel PowerPC处理器：ppc64le 实践 以下以服务器在无外网的情况下安装nginx为例 查看服务器版本 # cat /proc/version Linux version 3.10.0-514.26.2.el7.x86_64 (builder@kbuilder.dev.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-11) (GCC) ) #1 SMP Tue Jul 4 15:04:05 UTC 2017 这里查到CPU架构为x86_64、操作系统为ed Hat 4.8.5-11（这里查到的版本为Red Hat 4.8.5-11对应官方开发进度为Centos7.8，也可使用cat /etc/redhat-release 查看红帽的社区版本）、使用的包管理工具为RPM 下载相应Nginx离线包 进入nginx官网根据安装文档http://nginx.org/en/linux_packages.html找到源库http://nginx.org/packages，对应Centos7操作系统版本x86_64位找到安装包http://nginx.org/packages/centos/7/x86_64/RPMS/nginx-1.16.1-1.el7.ngx.x86_64.rpm 使用相应包管理工具安装Nginx # rpm -ivh nginx-1.16.1-1.el7.ngx.x86_64.rpm warning: nginx-1.16.1-1.el7.ngx.x86_64.rpm: Header V4 RSA/SHA1 Signature, key ID 7bd9bf62: NOKEY error: Failed dependencies: libc.so.6(GLIBC_2.14)(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 libc.so.6(GLIBC_2.17)(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 libcrypto.so.10(OPENSSL_1.0.2)(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 libcrypto.so.10(libcrypto.so.10)(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 libpcre.so.1()(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 libssl.so.10(libssl.so.10)(64bit) is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 openssl &gt;= 1.0.2 is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 systemd is needed by nginx-1:1.16.1-1.el7.ngx.x86_64 这里安装报错需要处理依赖程序，可根据提示中的信息去搜索指定版本依赖文件，如无报错则安装成功。依赖包可能存在与Centos源中，也可能存在Nginx软件源中。 进入相应镜像库下载所需要的依赖包 登录阿里云镜像站进入centos页面点击下载地址，根据上面查到的服务器版本进入相应目录搜索包https://mirrors.aliyun.com/centos/7/os/x86_64/Packages/或https://mirrors.aliyun.com/centos/7/extras/x86_64/Packages/ 也可以直接搜索相应包下载https://developer.aliyun.com/packageSearch 安装所有依赖包 # rpm -ivh * 若出现安装顺序问题，可按提示顺序一个个单独安装 源码安装 自建源在线安装 ","link":"https://mzqk.github.io/post/linux-chi-xian-an-zhuang-ying-yong/"},{"title":"Oracle数据库迁移","content":"数据库迁移 备份数据 expdp system/system@192.168.1.1/orcl directory=DATA_PUMP_DIR dumpfile=expdpfulldb.dmp logfile=expdp.log full=y 导出表空间 select 'create tablespace '||tablespace_name|| ' datafile '||'''/data/oracle/oradata/msczj/'||tablespace_name||'.dbf'''||' size '|| round(bytes / (1024 * 1024), 0)||'M;' total from dba_data_files 导入数据 impdp system/system directory=DATA_PUMP_DIR dumpfile=expdpfulldb.dmp logfile=impdp.log schemas=(业务表用户，多个使用逗号分隔) 设置定时备份任务 ","link":"https://mzqk.github.io/post/oracle-shu-ju-ku-qian-yi/"},{"title":"Ansible使用入门","content":"Ansible基础使用 准备工作 ssh免密登录 生成本地公私钥 上传私钥至被控服务器 验证登录 ssh-keygen ssh-copy-id -i ~/.ssh/id_rsa.pub remote_username@server_ip_address ssh remote_username@server_ip_address 添加被控服务器信息 echo &quot;first.example.org&quot; &gt;&gt; /etc/ansible/hosts Ad-Hoc Commands Ad-Hoc Commands 可以翻译为简短地指令。 $ ansible all -m ping server1 | SUCCESS =&gt; { &quot;changed&quot;: false, &quot;ping&quot;: &quot;pong&quot; } $ ansible all -m command -a &quot;echo Hello World&quot; server1 | SUCCESS | rc=0 &gt;&gt; Hello World 常用模块 ping setup command shell cron user、group cpoy file yum、apt service script Playbooks Playbooks 是 Ansible 的脚本 。 $ vi hello_world.yml --- - name: say 'hello world' hosts: all tasks: - name: echo 'hello world' command: echo 'hello world' register: result - name: print stdout debug: msg: &quot;&quot; $ ansible-playbook hello_world.yml PLAY [say 'hello world'] ******************************************************* TASK [setup] ******************************************************************* ok: [server1] TASK [echo 'hello world'] ****************************************************** changed: [server1] TASK [print stdout] ************************************************************ ok: [server1] =&gt; { &quot;msg&quot;: &quot;hello world&quot; } PLAY RECAP ********************************************************************* server1 : ok=3 changed=1 unreachable=0 failed=0 Roles Roles 可以降低 Playbooks 的复杂性，更可以增加 Playbooks 的可用性。 $ tree . . └── example_role ├── README.md # 说明文件 ├── defaults │ └── main.yml # 可被覆写的变数。 ├── files # 需复制到 Managed node 的档案。 ├── handlers │ └── main.yml # 主要的 handler。 ├── meta │ └── main.yml ├── tasks │ └── main.yml # 主要的 task。 ├── templates # 集中存放 Jinja2 模板的目录。 ├── tests │ ├── inventory │ └── test.yml └── vars └── main.yml # 不该被覆写的变数。 9 directories, 8 files 常用配置 Inventory文件 Ansible 可同时操作属于一个组的多台主机,组和主机之间的关系通过 inventory 文件配置. 默认的文件路径为 /etc/ansible/hosts ansible.cfg Ansible主要功能配置文件，默认的文件路径为/etc/ansible/ansible.cfg inventory 这个是默认库文件位置,脚本,或者存放可通信主机的目录: inventory = /etc/ansible/hosts library 这个是Ansible默认搜寻模块的位置: library = /usr/share/ansible remote_tmp Ansible 通过远程传输模块到远程主机,然后远程执行,执行后在清理现场.在有些场景下,你也许想使用默认路径希望像更换补丁一样使用, 这时候你可以使用这个选项.: remote_tmp = $HOME/.ansible/tmp 默认路径是在用户家目录下属的目录.Ansible 会在这个目录中使用一个随机的文件夹名称. forks 这个选项设置在与主机通信时的默认并行进程数.如果你有很多的主机, 高数值将会使得跨主机行为变快.默认值比较保守: forks=5 poll_interval 对于Ansible中的异步任务, 这个是设置定义,当具体的poll interval 没有定义时,多少时间回查一下这些任务的状态, 默认值是一个折中选择15秒钟.这个时间是个回查频率和任务完成叫回频率和当任务完成时的回转频率的这种: poll_interval=15 sudo_user 这个是sudo使用的默认用户,如果–sudo-user 没有特指或者’sudo_user’ 在Ansible playbooks中没有特指,在大多数的逻辑中 默认为: ‘root’ sudo_user=root ask_sudo_pass 类似 ask_pass,用来控制Ansible playbook 在执行sudo之前是否询问sudo密码.默认为no: ask_sudo_pass=True 如果用户使用的系统平台开启了sudo 密码的话,应该开绿这一参数 ask_pass 这个可以控制,Ansible 剧本playbook 是否会自动默认弹出弹出密码.默认为no:: ask_pass=True 如果使用SSH 密钥匙做身份认证.可能需要修改这一参数 remote_port 这个设置是你系统默认的远程SSH端口,如果不指定,默认为22号端口: remote_port = 22 roles_path roles 路径指的是’roles/’下的额外目录,用于playbook搜索Ansible roles.比如, 如果我们有个用于common roles源代码控制仓库和一个不同的 playbooks仓库,你也许会建立一个惯例去在 /opt/mysite/roles 里面查找roles.: roles_path = /opt/mysite/roles Roles将会在playbook目录中开始搜索.如果role没有找到,这个参数指定了其它可能的搜索路径. timeout 这个是默认SSH连接尝试超时时间: timeout = 10 remote_user 这是个ansible使用/usr/bin/ansible-playbook链接的默认用户名. 注意如果不指定,/usr/bin/ansible默认使用当前用户名称: remote_user = root log_path 如果出现在ansible.cfg文件中.Ansible 将会在选定的位置登陆执行信息.请留意用户运行的Ansible对于logfile有权限: log_path=/var/log/ansible.log 这个特性不是默认开启的.如果不设置,ansible将会吧模块加载纪录在系统日志系统中.不包含用密码. module_name 这个是/usr/bin/ansible的默认模块名（-m）. 默认是’command’模块. 之前提到过,command模块不支持shell变量,管道,配额. 所以也许你希望把这个参数改为’shell’: module_name = command executable 这个选项可以在sudo环境下产生一个shell交互接口. 用户只在/bin/bash的或者sudo限制的一些场景中需要修改.大部分情况下不需要修改: executable = /bin/bash private_key_file 如果你是用pem密钥文件而不是SSH 客户端或秘密啊认证的话,你可以设置这里的默认值,来避免每一次提醒设置密钥文件位置–ansible-private-keyfile: private_key_file=/path/to/file.pem display_skipped_hosts 如果设置为False,ansible 将不会显示任何跳过任务的状态.默认选项是现实跳过任务的状态:: display_skipped_hosts=True system_warnings 允许禁用系统运行ansible相关的潜在问题警告（不包括操作主机）: system_warnings = True *这个包括第三方库或者一些需要解决问题的警告. ","link":"https://mzqk.github.io/post/ansible-shi-yong-ru-men/"},{"title":"Tomcat 启用 SSL","content":"Tomcat 配置 SSL 申请证书 申请域名 绑定域名 证书申请 下载证书 配置 Tomcat 启用SSL conf/server.xml &lt;Connector port=&quot;8443&quot; protocol=&quot;HTTP/1.1&quot; port=&quot;8443&quot; SSLEnabled=&quot;true&quot; maxThreads=&quot;150&quot; scheme=&quot;https&quot; secure=&quot;true&quot; clientAuth=&quot;false&quot; sslProtocol=&quot;TLS&quot; /&gt; 修改为 &lt;Connector port=&quot;443&quot; protocol=&quot;org.apache.coyote.http11.Http11NioProtocol&quot; maxThreads=&quot;150&quot; SSLEnabled=&quot;true&quot;&gt; &lt;SSLHostConfig&gt; &lt;Certificate certificateKeystoreFile=&quot;conf/www.zhehangpiaowu.cn.pfx&quot;#请替换为pfx文件。 certificateKeystorePassword=&quot;0sXWUh0i&quot;#请替换为密码文件pfx-password.txt中的内容。 certificateKeystoreType=&quot;PKCS12&quot; /&gt; &lt;/SSLHostConfig&gt; &lt;/Connector&gt; 自动跳转至 HTTPS conf/web.xml &lt;login-config&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;auth-method&gt;CLIENT-CERT&lt;/auth-method&gt; &lt;realm-name&gt;Client Cert Users-only Area&lt;/realm-name&gt; &lt;/login-config&gt; &lt;security-constraint&gt; &lt;!-- Authorization setting for SSL --&gt; &lt;web-resource-collection &gt; &lt;web-resource-name &gt;SSL&lt;/web-resource-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/web-resource-collection&gt; &lt;user-data-constraint&gt; &lt;transport-guarantee&gt;CONFIDENTIAL&lt;/transport-guarantee&gt; &lt;/user-data-constraint&gt; &lt;/security-constraint&gt; 禁止IP访问 conf/server.xml &lt;Engine name=&quot;Catalina&quot; defaultHost=&quot;www.baidu.com&quot;&gt; #域名地址 &lt;Host name=&quot;www.baidu.com&quot; appBase=&quot;webapps&quot; unpackWARs=&quot;true&quot; autoDeploy=&quot;true&quot;&gt; ","link":"https://mzqk.github.io/post/tomcat-qi-yong-ssl/"},{"title":"Oracle 安装","content":"Linux 安装 Oracle软件 环境准备 创建用户和用户组 groupadd oinstall groupadd dba useradd -g oinstall -G dba oracle passwd oracle 安装依赖 yum install gcc make binutils gcc-c++ \\ compat-libstdc++-33elfutils-libelf-devel \\ elfutils-libelf-devel-static ksh libaio \\ libaio-develnumactl-devel sysstat unixODBC \\ unixODBC-devel pcre-devel –y 内核参数调整 关闭selinux /etc/selinux/config # 修改配置文件参数 SELINUX=disabled setenforce 0 修改系统参数（可选） /etc/sysctl.conf fs.aio-max-nr = 1048576 fs.file-max = 6815744 #若安装数据库有ORA-27102报错，可调大kernel.shmall、kernel.shmmax值 kernel.shmall = 4294967296 #shmall 是全部允许使用的共享内存大小 kernel.shmmax = 68719476736 #shmmax 是单个段允许使用的大小，为本机物理内存的一半，单位为byte。 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 262144 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576 sysctl -p 修改用户限制（可选） /etc/security/limits.conf # 末尾添加 oracle soft nproc 2047 oracle hard nproc 16384 oracle soft nofile 1024 oracle hard nofile 65536 oracle soft stack 10240 /etc/pam.d/login # 末尾添加 session required /lib64/security/pam_limits.so session required pam_limits.so /etc/profile # 末尾添加 if [ $USER = &quot;oracle&quot; ]; then if [ $SHELL = &quot;/bin/ksh&quot; ]; then ulimit -p 16384 ulimit -n 65536 else ulimit -u 16384 -n 65536 fi fi 配置用户环境 创建软件安装路径 # 目录与配置文件相关，请按需修改 mkdir -p /data/oracle/product/11.2.0 mkdir /data/oracle/oradata mkdir /data/oracle/inventory mkdir /data/oracle/fast_recovery_area chown -R oracle:oinstall /data/oracle chmod -R 775 /data/oracle 配置用户环境变量 .bash_profile # 末尾添加 ORACLE_BASE=/data/oracle ORACLE_HOME=$ORACLE_BASE/product/11.2.0 ORACLE_SID=orcl # 实例名与配置文件相关，请按需修改 PATH=$PATH:$ORACLE_HOME/bin export ORACLE_BASE ORACLE_HOME ORACLE_SID PATH source .bash_profile 配置信息 数据库响应文件 db_install.rsp # 静默安装，无需图形界面 oracle.install.option=INSTALL_DB_SWONLY #主机名修改 ORACLE_HOSTNAME=centos36181 UNIX_GROUP_NAME=oinstall INVENTORY_LOCATION=/data/oracle/inventory SELECTED_LANGUAGES=en,zh_CN ORACLE_HOME=/data/oracle/product/11.2.0 ORACLE_BASE=/data/oracle oracle.install.db.InstallEdition=EE oracle.install.db.DBA_GROUP=dba oracle.install.db.OPER_GROUP=dba # 客户端字符串 oracle.install.db.config.starterdb.characterSet=ZHS16GBK DECLINE_SECURITY_UPDATES=true 库实例响应文件 dbca.rsp # 选择创建数据库模式 [CREATEDATABASE] # 全局数据库的名字=SID+主机域名 GDBNAME = &quot;orcl.test&quot; # 对应的实例名字 SID = &quot;orcl&quot; # 建库用的模板文件 TEMPLATENAME = &quot;General_Purpose.dbc&quot; # SYS管理员密码 SYSPASSWORD = &quot;123456&quot; # SYSTEM管理员密码 SYSTEMPASSWORD = &quot;123456&quot; # 数据文件存放目录 DATAFILEDESTINATION =/data/oracle/oradata # 恢复数据存放目录 RECOVERYAREADESTINATION=/data/oracle/fast_recovery_area # 字符集，重要!!! 建库后一般不能更改，所以建库前要确定清楚。 # (CHARACTERSET = &quot;AL32UTF8&quot; NATIONALCHARACTERSET= &quot;UTF8&quot;) CHARACTERSET = &quot;ZHS16GBK&quot; # oracle使用物理内存80%（可选） TOTALMEMORY = &quot;1638&quot; 软件安装与卸载 安装数据库 # 使用oracle用户 ./runInstaller -silent -responseFile /database/response/db_install.rsp -ignorePrereq 以 root 用户的身份执行以下脚本: 1. /data/oracle/inventory/orainstRoot.sh 2. /data/oracle/product/11.2.0/root.sh 配置监听 # 使用oracle用户 netca /silent /responseFile /database/response/netca.rsp 安装库实例 # 使用oracle用户 dbca -silent -responseFile /database/response/dbca.rsp 卸载数据库 dbca -silent -deleteDatabase -responseFile /database/response/dbca.rsp 常见问题处理 ORA-12514: TNS:listener does not currently know of service requested in connect 修改文件/data/oracle/product/11.2.0/network/admin/listener.ora SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = orcl) (SID_NAME = orcl) ) ) ","link":"https://mzqk.github.io/post/oracle-an-zhuang/"},{"title":"Nginx入门","content":"Nginx入门 Nginx简介 简介 Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，其特点是占有内存少，并发能力强。 特点 高并发 内存消耗少 成本低廉 配置简单 内置健康检查功能 节省带宽 稳定性高 支持热部署 常见WEB服务器 Apache Lighttpd Tomcat Tengine IBM WebSphere IIS LVS HAProxy Nginx安装 在线安装 Linux apt install nginx yum install nginx 查询默认配置文件 nginx -t Windows 官网下载ngixn文件解压至制定目录 源码安装 下载源码包（包含基础依赖包，如prce库） ./configure 根据需求进行配置 make install 指定目录安装 wget http://nginx.org/download/nginx-1.16.1.tar.gz tar -zxvf nginx-1.16.1.tar.gz ./configure --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module make &amp;&amp; make install 官方编译参数 Nginx基础 基础使用 启动 nginx #正常启动应用 nginx -c /etc/nginx/conf/nginx.conf #指定配置文件启动 停止 nginx -s stop #停止nginx应用 pkill -9 nginx #停止nginx所有进程 kill -INT `cat /run/nginx.pid` #指定pid发起停止信号 平滑重启 nginx -s reload #重启应用 kill -HUP `cat /run/nginx.pid` #指定pid发起重启信号 基础配置 目录结构 /etc/nginx/ ├── conf.d ├── default.d ├── fastcgi.conf ├── fastcgi.conf.default ├── fastcgi_params ├── fastcgi_params.default ├── koi-utf ├── koi-win ├── mime.types ├── mime.types.default ├── nginx.conf ├── nginx.conf.default ├── nginx.conf.rpmnew ├── scgi_params ├── scgi_params.default ├── uwsgi_params ├── uwsgi_params.default └── win-utf /usr/share/nginx/ ├── html │ ├── 404.html │ ├── 50x.html │ ├── 50x.html_bak │ ├── en-US -&gt; ../../doc/HTML/en-US │ ├── icons │ │ └── poweredby.png -&gt; ../../../pixmaps/poweredby.png │ ├── img -&gt; ../../doc/HTML/img │ ├── index.html -&gt; ../../doc/HTML/index.html │ ├── index.html_bak │ ├── nginx-logo.png │ └── poweredby.png -&gt; nginx-logo.png └── modules ├── mod-http-image-filter.conf ├── mod-http-perl.conf ├── mod-http-xslt-filter.conf ├── mod-mail.conf └── mod-stream.conf /var/log/nginx/ ├── access.log └── error.log /run/nginx.pid 配置文件 #主配置 user www www; #使用用户和组 worker_processes auto; #工作进程数 error_log /var/log/nginx/error.log; #错误日志保存位置 pid /run/nginx.pid; #进程pid存放位置 include /usr/share/nginx/modules/*.conf; #模块加载目录 #事件模型 events { worker_connections 1024; #最大连接数 } #http服务器 http { log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; #日志输出格式 access_log /var/log/nginx/access.log main; #标准日志保存位置 sendfile on; #开启高效文件传输模式，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。 tcp_nopush on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用 tcp_nodelay on; #将连接转变为长连接 keepalive_timeout 65; #长连接超时时间，单位是秒 types_hash_max_size 2048; include /etc/nginx/mime.types; #设定mime类型,类型由mime.type文件定义 default_type application/octet-stream; include /etc/nginx/conf.d/*.conf; #加载其他配置文件 # 虚拟主机 server { listen 80 default_server; listen [::]:80 default_server; #监听端口 server_name _; #域名，可以有多个 root /usr/share/nginx/html; #web服务器根目录 include /etc/nginx/default.d/*.conf; #加载其他配置文件 location / { proxy_pass http://127.0.0.1/; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #获取用户真实IP } error_page 404 /404.html; location = /40x.html { } error_page 500 502 503 504 /50x.html; location = /50x.html { } } } 基础优化 日志文件配置 #!/bin/bash #脚本用于切割nginx日志文件 #请配置脚本为每天00:00启动 #crontab -e 00 00 * * * /bin/bash /root/spilt_nginx_log.sh #设置nginx日志文件目录 log_path=&quot;/var/log/nginx/&quot; #根据时间切割日志文件 mkdir -p ${log_path}${date -d &quot;yesterday&quot; +&quot;%Y%m&quot;} mv ${log_path}access.log ${log_path}${date -d &quot;yesterday&quot; +&quot;%Y%m&quot;}/access_${date -d &quot;yesterday&quot; +&quot;%Y%m%d&quot;}.log #重启nginx kill -HUP `cat /run/nginx.pid` 压缩输出配置 gzip on; gzip_mini_length 1k; gzip_buffer 4 16k; gzip_http_version 1.1; gzip_comp_level 2; gzip_tesxt_plain application/x-javascript text/css application/xml; gzip_vary on; 缓存配置 location ~ .*\\.{git|jpg|jpeg|png|bmp|swf}$ { expires 30d; } location ~ .*\\.{js|css}?$ { expires 1h; } URL重写 #根据浏览器标识，访问资源重定向到指定文件目录（以下为IE) if ($http_user_agent ~ MSIE ) { rewrite ^(.*)$ /msie/$1 break; } #将移动客户端的请求重定向到其他服务器 if ($http_user_agent ~* '(iphone|ipod)' ) { rewrite ^.+ http://mobile.site.com$uri; } #.用户使用POST方式请求数据时候，返回405： if ($request_method = POST ) { return 405; } #访问xxxx时重定向到xxxx目录 location /xxxx { rewrite ^/xxxx/.*$ /xxxx permanent; } Nginx常用功能 反向代理 http{ server{ listen 80; server_name localhost; location / { proxy_pass http://localhost:8080; } } 负载均衡 官方说明 http { upstream myproject { server 127.0.0.1:8000 weight=3; server 127.0.0.1:8001; server 127.0.0.1:8002; server 127.0.0.1:8003; } server { listen 80; server_name www.domain.com; location / { proxy_pass http://myproject; } } } 正向代理 http{ server{ listen 8888; location / { resolver 8.8.8.8; proxy_pass http://$http_host$request_uri; } } } HTTP服务器（SSL） 官方说明 http { server { listen 443; server_name localhost; ssl on; ssl_certificate /usr/local/nginx/conf/cert.pem; ssl_certificate_key /usr/local/nginx/conf/cert.key; } } 文件服务器 http{ server{ listen 80; server_name localhost; root /usr/share/nginx/html/; } } 负载均衡 http{ upstream myproject { server 192.168.1.112:8001; server 192.168.1.112:8002; server 192.168.1.112:8003; } proxy_buffering on; proxy_cache_valid any 10m; proxy_cache_path /data/cache levels=1:2 keys_zone=my_cache:10m max_size=1000m inactive=600m; proxy_temp_path /data/temp; proxy_buffer_size 4k; proxy_buffers 100 8k; server { listen 80; server_name localhost jeson.t.imooc.io; location / { proxy_cache my_cache; #开启缓存 proxy_pass http://myproject; proxy_cache_key $host$uri$is_args$args; #定义缓存的key } } Nginx模块 HTTP模块 ngx_http_core_module ngx_http_access_module ngx_http_addition_module ngx_http_api_module ngx_http_auth_basic_module ngx_http_auth_jwt_module ngx_http_auth_request_module ngx_http_autoindex_module ngx_http_browser_module ngx_http_charset_module ngx_http_dav_module ngx_http_empty_gif_module ngx_http_f4f_module ngx_http_fastcgi_module ngx_http_flv_module ngx_http_geo_module ngx_http_geoip_module ngx_http_grpc_module ngx_http_gunzip_module ngx_http_gzip_module ngx_http_gzip_static_module ngx_http_headers_module ngx_http_hls_module ngx_http_image_filter_module ngx_http_index_module ngx_http_js_module ngx_http_keyval_module ngx_http_limit_conn_module ngx_http_limit_req_module ngx_http_log_module ngx_http_map_module ngx_http_memcached_module ngx_http_mirror_module ngx_http_mp4_module ngx_http_perl_module ngx_http_proxy_module ngx_http_random_index_module ngx_http_realip_module ngx_http_referer_module ngx_http_rewrite_module ngx_http_scgi_module ngx_http_secure_link_module ngx_http_session_log_module ngx_http_slice_module ngx_http_spdy_module ngx_http_split_clients_module ngx_http_ssi_module ngx_http_ssl_module ngx_http_status_module ngx_http_stub_status_module ngx_http_sub_module ngx_http_upstream_module ngx_http_upstream_conf_module ngx_http_upstream_hc_module ngx_http_userid_module ngx_http_uwsgi_module ngx_http_v2_module ngx_http_xslt_module 邮箱模块 ngx_mail_core_module ngx_mail_auth_http_module ngx_mail_proxy_module ngx_mail_ssl_module ngx_mail_imap_module ngx_mail_pop3_module ngx_mail_smtp_module Strean模块 ngx_stream_core_module ngx_stream_access_module ngx_stream_geo_module ngx_stream_geoip_module ngx_stream_js_module ngx_stream_keyval_module ngx_stream_limit_conn_module ngx_stream_log_module ngx_stream_map_module ngx_stream_proxy_module ngx_stream_realip_module ngx_stream_return_module ngx_stream_split_clients_module ngx_stream_ssl_module ngx_stream_ssl_preread_module ngx_stream_upstream_module ngx_stream_upstream_hc_module ngx_stream_zone_sync_module SLB实例 产品架构 基础架构说明 阿里云当前提供四层和七层的负载均衡服务。 四层采用开源软件LVS（Linux Virtual Server）+ keepalived的方式实现负载均衡，并根据云计算需求对其进行了个性化定制。 七层采用Tengine实现负载均衡。Tengine是由淘宝网发起的Web服务器项目，它在Nginx的基础上，针对有大访问量的网站需求，添加了很多高级功能和特性。 如下图所示，各个地域的四层负载均衡实际上是由多台LVS机器部署成一个LVS集群来运行的。采用集群部署模式极大地保证了异常情况下负载均衡服务的可用性、稳定性与可扩展性。 LVS集群内的每台LVS都会进行会话，通过组播报文同步到该集群内的其它LVS机器上，从而实现LVS集群内各台机器间的会话同步。如下图所示，当客户端向服务端传输三个数据包后，在LVS1上建立的会话A开始同步到其它LVS机器上。图中实线表示现有的连接，图中虚线表示当LVS1出现故障或进行维护时，这部分流量会走到一台可以正常运行的机器LVS2上。因而负载均衡集群支持热升级，并且在机器故障和集群维护时最大程度对用户透明，不影响用户业务。 说明 对于连接未建立（三次握手未完成），或者已建立连接但未触发会话同步机制，热升级不保证连接不中断，需要依靠客户端重新发起连接。 入网流量路径 对于入网流量，负载均衡会根据用户在控制台或API上配置的转发策略，对来自前端的访问请求进行转发和处理，数据流转如图 1所示。 图 1. 入网流量路径 TCP/UDP协议和HTTP/HTTPS协议的流量都需要经过LVS集群进行转发。 LVS集群内的每一台节点服务器均匀地分配海量访问请求，并且每一台节点服务器之间都有会话同步策略，以保证高可用。 如果相应的负载均衡实例服务端口使用的是四层协议（TCP或UDP），那么LVS集群内每个节点都会根据负载均衡实例负载均衡策略，将其承载的服务请求按策略直接分发到后端ECS服务器。 如果相应的负载均衡实例服务端口使用的是七层HTTP协议，那么LVS集群内每个节点会先将其承载的服务请求均分到Tengine集群，Tengine集群内的每个节点再根据负载均衡策略，将服务请求按策略最终分发到后端ECS服务器。 如果相应的负载均衡实例服务端口使用的是七层HTTPS协议，与上述HTTP处理过程类似，差别是在按策略将服务请求最终分发到后端ECS服务器前，先调用Key Server进行证书验证及数据包加解密等前置操作。 出网流量路径 负载均衡SLB和后端ECS之间是通过内网进行通信的。 如果ECS仅仅处理来自负载均衡的请求，可以不购买公网带宽（ECS公网IP/弹性公网IP/NAT网关等）。 说明 早期创建的一些ECS上直接分配了公网IP（ifconfig中可见接口上分配的公网ip地址），此类ECS如果仅通过SLB对外提供服务，即便在公网接口（网卡）上看到有流量统计，也不会产生ECS的公网费用。 如果需要直接通过后端ECS对外提供服务，或后端ECS有访问外网的需求， 那么需要相应的配置或购买ECS公网IP/弹性公网IP/NAT网关等服务。 ECS的公网流量访问路径如图 2所示。 图 2. 出网流量路径 总体原则：流量从哪里进来，就从哪里出去。 通过负载均衡进入的流量在负载均衡SLB上限速/计费，仅收取出方向流量费用，入方向流量不收取（在未来可能会改变），SLB到ECS之间是阿里云内网通信，不收取流量费用。 来自弹性公网IP/NAT网关的流量，分别在弹性公网IP/NAT网关上进行限速/计费，如果在购买ECS时选择了公网带宽，限速/计费点在ECS上。 负载均衡SLB仅提供被动访问公网的能力，即后端ECS只能在收到通过负载均衡SLB转发来的公网的请求时，才能访问公网回应该请求，如后端ECS希望主动发起公网访问，则需要配置/购买ECS公网带宽、弹性公网IP或NAT网关来实现。 ECS公网带宽（购买ECS时配置）、弹性公网IP、NAT网关均可以实现ECS的双向公网访问（访问或被访问），但没有流量分发和负载均衡的能力。 快速入门 ​ ","link":"https://mzqk.github.io/post/nginx-ji-chu-ru-men/"},{"title":"用 Docker 部署 Seafile 服务","content":"用 Docker 部署 Seafile 服务 快速开始 安装 docker-compose 因为 Seafile v7.x.x 容器是通过 docker-compose 命令运行的，所以您应该先在服务器上安装该命令。 # for CentOS yum install docker-compose -y # for Ubuntu apt-get install docker-compose -y 下载并修改 docker-compose.yml 下载 docker-compose.yml 示例文件到您的服务器上，然后根据您的实际环境修改该文件。尤其是以下几项配置： MySQL root 用户的密码 (MYSQL_ROOT_PASSWORD and DB_ROOT_PASSWD) 持久化存储 MySQL 数据的 volumes 目录 (volumes) 持久化存储 Seafile 数据的 volumes 目录 (volumes) 持久化存储 Elasticsearch 索引数据的 volumes 目录 (volumes) 启动 Seafile 服务 执行以下命令启动 Seafile 服务 docker-compose up -d 需要等待几分钟，等容器首次启动时的初始化操作完成后，您就可以在浏览器上访问http://seafile.example.com 来打开 Seafile 主页。 **注意：您应该在 **docker-compose.yml文件所在的目下执行以上命令。 安装授权文件(seafile-license.txt) 如果您已经向 Seafile 软件商购买了专业版的授权文件seafile-license.txt，您只需要将该授权文件拷贝至 Seafile 数据持久化目录中的seafile/目录下，然后重启docker容器，即可完成授权文件的安装。 假如，Seafile 数据持久化目录为/opt/seafile-data，那么，在您的宿主机上执行以下操作： cp /path/to/seafile-license.txt /opt/seafile-data/seafile/ 然后重启这个容器： docker-compose restart 更多配置项 自定义管理员用户名和密码 默认的管理员账号是 me@example.com 并且该账号的密码是 asecret，您可以在 docker-compose.yml 中配置不同的用户名和密码，为此您需要做如下配置： seafile: ... environment: ... - SEAFILE_ADMIN_EMAIL=me@example.com - SEAFILE_ADMIN_PASSWORD=a_very_secret_password ... 使用 Let's encrypt SSL 证书 如果您把 SEAFILE_SERVER_LETSENCRYPT 设置为 true，该容器将会自动为您申请一个 letsencrypt 机构颁发的 SSL 证书，并开启 https 访问，为此您需要做如下配置： seafile: ... ports: - &quot;80:80&quot; - &quot;443:443&quot; ... environment: ... - SEAFILE_SERVER_LETSENCRYPT=true - SEAFILE_SERVER_HOSTNAME=seafile.example.com ... 如果您想要使用自己的 SSL 证书，而且如果用来持久化存储 Seafile 数据的目录为 /opt/seafile-data，您可以做如下处理： 创建 /opt/seafile-data/ssl 目录，然后拷贝您的证书文件和密钥文件到ssl目录下。 假设您的站点名称是 seafile.example.com，那么您的证书名称必须就是 seafile.example.com.crt，密钥文件名称就必须是 seafile.example.com.key。 修改 Seafile 服务的配置 Seafile 的配置文件存放在 shared/seafile/conf 目录下，您可以根据Seafile 手册的指导来修改这些配置项。 一旦修改了配置文件，您需要重启服务以使其生效： docker-compose restart 查找日志 Seafile 容器中 Seafile 服务本身的日志文件存放在 /shared/logs/seafile 目录下，或者您可以在宿主机上 Seafile 容器的卷目录中找到这些日志，例如：/opt/seafile-data/logs/seafile 同样 Seafile 容器的系统日志存放在 /shared/logs/var-log 目录下，或者宿主机目录 /opt/seafile-data/logs/var-log。 增加一个新的管理员 确保各容器正常运行，然后执行以下命令： docker exec -it seafile /opt/seafile/seafile-server-latest/reset-admin.sh 根据提示输入用户名和密码，您现在有了一个新的管理帐户。 Seafile 目录结构 /shared 共享卷的挂载点,您可以选择在容器外部存储某些持久性信息.在这个项目中，我们会在外部保存各种日志文件和上传数据。 这使您可以轻松重建容器而不会丢失重要信息。 /shared/seafile: Seafile 服务的配置文件以及数据文件 /shared/logs: 日志目录 /shared/logs/var-log: 我们将容器内的/var/log链接到本目录。您可以在/shared/logs/var-log/nginx/中找到 nginx 的日志文件 /shared/logs/seafile: Seafile 服务运行产生的日志文件目录。比如您可以在 /shared/logs/seafile/seafile.log 文件中看到 seaf-server 的日志 /shared/ssl: 存放证书的目录，默认不存在 升级 Seafile 服务 如果要升级 Seafile 服务到最新版本： docker pull docker.seafile.top/seafileltd/seafile-pro-mc:latest docker-compose down docker-compose up -d 备份和恢复 目录结构 我们假设您的 seafile 数据卷路径是 /opt/seafile-data，并且您想将备份数据存放到 /opt/seafile-backup 目录下。 您可以创建一个类似以下 /opt/seafile-backup 的目录结构： /opt/seafile-backup ---- databases/ 用来存放 MySQL 容器的备份数据 ---- data/ 用来存放 Seafile 容器的备份数据 要备份的数据文件： /opt/seafile-data/seafile/conf # configuration files /opt/seafile-data/seafile/seafile-data # data of seafile /opt/seafile-data/seafile/seahub-data # data of seahub 备份数据 步骤： 备份 MySQL 数据库数据； 备份 Seafile 数据目录； 备份数据库： # 建议每次将数据库备份到一个单独的文件中。至少在一周内不要覆盖旧的数据库备份。 cd /opt/seafile-backup/databases docker exec -it seafile-mysql mysqldump -uroot --opt ccnet_db &gt; ccnet_db.sql docker exec -it seafile-mysql mysqldump -uroot --opt seafile_db &gt; seafile_db.sql docker exec -it seafile-mysql mysqldump -uroot --opt seahub_db &gt; seahub_db.sql 备份 Seafile 资料库数据： 直接复制整个数据目录 cp -R /opt/seafile-data/seafile /opt/seafile-backup/data/ cd /opt/seafile-backup/data &amp;&amp; rm -rf ccnet 使用 rsync 执行增量备份 rsync -az /opt/seafile-data/seafile /opt/seafile-backup/data/ cd /opt/seafile-backup/data &amp;&amp; rm -rf ccnet 恢复数据 恢复数据库： docker cp /opt/seafile-backup/databases/ccnet_db.sql seafile-mysql:/tmp/ccnet_db.sql docker cp /opt/seafile-backup/databases/seafile_db.sql seafile-mysql:/tmp/seafile_db.sql docker cp /opt/seafile-backup/databases/seahub_db.sql seafile-mysql:/tmp/seahub_db.sql docker exec -it seafile-mysql /bin/sh -c &quot;mysql -uroot ccnet_db &lt; /tmp/ccnet_db.sql&quot; docker exec -it seafile-mysql /bin/sh -c &quot;mysql -uroot seafile_db &lt; /tmp/seafile_db.sql&quot; docker exec -it seafile-mysql /bin/sh -c &quot;mysql -uroot seahub_db &lt; /tmp/seahub_db.sql&quot; 恢复 seafile 数据： cp -R /opt/seafile-backup/data/* /opt/seafile-data/seafile/ 垃圾回收 在 seafile 中，当文件被删除时，组成这些文件的块数据不会立即删除，因为可能有其他文件也会引用这些块数据(用于去重功能的实现)。为了真正删除无用的块数据，还需要额外运行&quot;GC&quot;程序。GC 会自动检测到哪些数据块不再被任何文件所引用，并清除它们。 GC 脚本被放在docker容器的 /scripts 目录下。执行 GC 的方法很简单：docker exec seafile /scripts/gc.sh。对于社区版来说，该程序会暂停 Seafile 服务，但这是一个相对较快的程序，一旦程序运行完成，Seafile 服务也会自动重新启动。而专业版提供了在线运行 GC 的功能，不会暂停 Seafile 服务。 问题排查 您可以运行 docker exec 之类的docker命令来查找错误。 docker exec -it seafile /bin/bash ","link":"https://mzqk.github.io/post/yong-docker-bu-shu-seafile-fu-wu/"},{"title":"kubeadm安装k8s","content":"kubeadm安装k8s kubeadm是官方社区推出的一个用于快速部署kubernetes集群的工具。 准备环境 关闭防火墙： $ systemctl stop firewalld $ systemctl disable firewalld 关闭selinux： $ sed -i 's/enforcing/disabled/' /etc/selinux/config $ setenforce 0 关闭swap： $ swapoff -a $ 临时 $ vim /etc/fstab $ 永久 添加主机名与IP对应关系（记得设置主机名）： $ cat /etc/hosts 192.168.31.62 k8s-master 192.168.31.62 k8s-node1 192.168.31.63 k8s-node2 将桥接的IPv4流量传递到iptables的链： $ cat &gt; /etc/sysctl.d/k8s.conf &lt;&lt; EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF $ sysctl --system 所有节点安装Docker/kubeadm/kubelet 安装Docker Kubernetes默认CRI（容器运行时）为Docker，因此先安装Docker。 $ wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo $ yum -y install docker-ce-18.06.1.ce-3.el7 $ systemctl enable docker &amp;&amp; systemctl start docker $ docker --version Docker version 18.06.1-ce, build e68fc7a 添加阿里云YUM软件源 $ cat &gt; /etc/yum.repos.d/kubernetes.repo &lt;&lt; EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 安装kubeadm，kubelet和kubectl 由于版本更新频繁，这里指定版本号部署： $ yum install -y kubelet-1.13.3 kubeadm-1.13.3 kubectl-1.13.3 $ systemctl enable kubelet 部署Kubernetes Master $ kubeadm init \\ --apiserver-advertise-address=192.168.31.62 \\ --image-repository registry.aliyuncs.com/google_containers \\ --kubernetes-version v1.13.3 \\ --service-cidr=10.1.0.0/16\\ --pod-network-cidr=10.244.0.0/16 这个初始化过程需要几分钟，具体时间取决于你的网络。 由于默认拉取镜像地址k8s.gcr.io国内无法访问，这里指定阿里云镜像仓库地址。 使用kubectl工具： mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config $ kubectl get nodes 安装Pod网络插件（CNI） $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/a70459be0084506e4ec919aa1c114638878db11b/Documentation/kube-flannel.yml 确保能够访问到quay.io这个registery。 加入Kubernetes Node 向集群添加新节点，执行在kubeadm init输出的kubeadm join命令： $ kubeadm join 192.168.31.64:6443 --token l79g5t.6ov4jkddwqki1dxe --discovery-token-ca-cert-hash sha256:4f07f9068c543130461c9db368d62b4aabc22105451057f887defa35f47fa076 测试kubernetes集群 在Kubernetes集群中创建一个pod，验证是否正常运行： $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 --type=NodePort $ kubectl get pod,svc 访问地址：http://NodeIP:Port ","link":"https://mzqk.github.io/post/kubeadm-an-zhuang-k8s/"},{"title":"二进制部署 Kubernetes 集群","content":"二进制部署 Kubernetes 集群 安装Etcd 使用cfssl来生成自签证书，先下载cfssl工具： wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 chmod +x cfssl_linux-amd64 cfssljson_linux-amd64 cfssl-certinfo_linux-amd64 mv cfssl_linux-amd64 /usr/local/bin/cfssl mv cfssljson_linux-amd64 /usr/local/bin/cfssljson mv cfssl-certinfo_linux-amd64 /usr/bin/cfssl-certinfo 生成证书 创建以下三个文件： # cat ca-config.json { &quot;signing&quot;: { &quot;default&quot;: { &quot;expiry&quot;: &quot;87600h&quot; }, &quot;profiles&quot;: { &quot;www&quot;: { &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] } } } } # cat ca-csr.json { &quot;CN&quot;: &quot;etcd CA&quot;, &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot; } ] } # cat server-csr.json { &quot;CN&quot;: &quot;etcd&quot;, &quot;hosts&quot;: [ &quot;192.168.31.63&quot;, &quot;192.168.31.65&quot;, &quot;192.168.31.66&quot; ], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot; } ] } 生成证书： cfssl gencert -initca ca-csr.json | cfssljson -bare ca - cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=www server-csr.json | cfssljson -bare server # ls *pem ca-key.pem ca.pem server-key.pem server.pem 部属Etcd 二进制包下载地址：https://github.com/coreos/etcd/releases/tag/v3.2.12 创建etcd配置文件： # cat /opt/etcd/cfg/etcd #[Member] ETCD_NAME=&quot;etcd01&quot; ETCD_DATA_DIR=&quot;/var/lib/etcd/default.etcd&quot; ETCD_LISTEN_PEER_URLS=&quot;https://192.168.31.63:2380&quot; ETCD_LISTEN_CLIENT_URLS=&quot;https://192.168.31.63:2379&quot; #[Clustering] ETCD_INITIAL_ADVERTISE_PEER_URLS=&quot;https://192.168.31.63:2380&quot; ETCD_ADVERTISE_CLIENT_URLS=&quot;https://192.168.31.63:2379&quot; ETCD_INITIAL_CLUSTER=&quot;etcd01=https://192.168.31.63:2380,etcd02=https://192.168.31.65:2380,etcd03=https://192.168.31.66:2380&quot; ETCD_INITIAL_CLUSTER_TOKEN=&quot;etcd-cluster&quot; ETCD_INITIAL_CLUSTER_STATE=&quot;new&quot; ETCD_NAME 节点名称 ETCD_DATA_DIR 数据目录 ETCD_LISTEN_PEER_URLS 集群通信监听地址 ETCD_LISTEN_CLIENT_URLS 客户端访问监听地址 ETCD_INITIAL_ADVERTISE_PEER_URLS 集群通告地址 ETCD_ADVERTISE_CLIENT_URLS 客户端通告地址 ETCD_INITIAL_CLUSTER 集群节点地址 ETCD_INITIAL_CLUSTER_TOKEN 集群Token ETCD_INITIAL_CLUSTER_STATE 加入集群的当前状态，new是新集群，existing表示加入已有集群 systemd管理etcd： # cat /usr/lib/systemd/system/etcd.service [Unit] Description=Etcd Server After=network.target After=network-online.target Wants=network-online.target [Service] Type=notify EnvironmentFile=/opt/etcd/cfg/etcd ExecStart=/opt/etcd/bin/etcd \\ --name=${ETCD_NAME} \\ --data-dir=${ETCD_DATA_DIR} \\ --listen-peer-urls=${ETCD_LISTEN_PEER_URLS} \\ --listen-client-urls=${ETCD_LISTEN_CLIENT_URLS},http://127.0.0.1:2379 \\ --advertise-client-urls=${ETCD_ADVERTISE_CLIENT_URLS} \\ --initial-advertise-peer-urls=${ETCD_INITIAL_ADVERTISE_PEER_URLS} \\ --initial-cluster=${ETCD_INITIAL_CLUSTER} \\ --initial-cluster-token=${ETCD_INITIAL_CLUSTER_TOKEN} \\ --initial-cluster-state=new \\ --cert-file=/opt/etcd/ssl/server.pem \\ --key-file=/opt/etcd/ssl/server-key.pem \\ --peer-cert-file=/opt/etcd/ssl/server.pem \\ --peer-key-file=/opt/etcd/ssl/server-key.pem \\ --trusted-ca-file=/opt/etcd/ssl/ca.pem \\ --peer-trusted-ca-file=/opt/etcd/ssl/ca.pem Restart=on-failure LimitNOFILE=65536 [Install] WantedBy=multi-user.target 把刚才生成的证书拷贝到配置文件中的位置: cp ca*pem server*pem /opt/etcd/ssl 启动并设置开启启动： # systemctl start etcd # systemctl enable etcd 都部署完成后，检查etcd集群状态： # /opt/etcd/bin/etcdctl \\ --ca-file=ca.pem --cert-file=server.pem --key-file=server-key.pem \\ --endpoints=&quot;https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379&quot; \\ cluster-health member 18218cfabd4e0dea is healthy: got healthy result from https://192.168.31.63:2379 member 541c1c40994c939b is healthy: got healthy result from https://192.168.31.65:2379 member a342ea2798d20705 is healthy: got healthy result from https://192.168.31.66:2379 cluster is healthy 在Node安装Docker # yum install -y yum-utils device-mapper-persistent-data lvm2 # yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # yum install docker-ce -y # curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://bc437cce.m.daocloud.io # systemctl start docker # systemctl enable docker 部署Flannel网络 Falnnel要用etcd存储自身一个子网信息，所以要保证能成功连接Etcd，写入预定义子网段： # /opt/etcd/bin/etcdctl \\ --ca-file=ca.pem --cert-file=server.pem --key-file=server-key.pem \\ --endpoints=&quot;https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379&quot; \\ set /coreos.com/network/config '{ &quot;Network&quot;: &quot;172.17.0.0/16&quot;, &quot;Backend&quot;: {&quot;Type&quot;: &quot;vxlan&quot;}}' 下载二进制包： # wget https://github.com/coreos/flannel/releases/download/v0.10.0/flannel-v0.10.0-linux-amd64.tar.gz # tar zxvf flannel-v0.9.1-linux-amd64.tar.gz # mv flanneld mk-docker-opts.sh /opt/kubernetes/bin 配置Flannel： # cat /opt/kubernetes/cfg/flanneld FLANNEL_OPTIONS=&quot;--etcd-endpoints=https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379 -etcd-cafile=/opt/etcd/ssl/ca.pem -etcd-certfile=/opt/etcd/ssl/server.pem -etcd-keyfile=/opt/etcd/ssl/server-key.pem&quot; systemd管理Flannel： # cat /usr/lib/systemd/system/flanneld.service [Unit] Description=Flanneld overlay address etcd agent After=network-online.target network.target Before=docker.service [Service] Type=notify EnvironmentFile=/opt/kubernetes/cfg/flanneld ExecStart=/opt/kubernetes/bin/flanneld --ip-masq $FLANNEL_OPTIONS ExecStartPost=/opt/kubernetes/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/subnet.env Restart=on-failure [Install] WantedBy=multi-user.target 配置Docker启动指定子网段： # cat /usr/lib/systemd/system/docker.service [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target firewalld.service Wants=network-online.target [Service] Type=notify EnvironmentFile=/run/flannel/subnet.env ExecStart=/usr/bin/dockerd $DOCKER_NETWORK_OPTIONS ExecReload=/bin/kill -s HUP $MAINPID LimitNOFILE=infinity LimitNPROC=infinity LimitCORE=infinity TimeoutStartSec=0 Delegate=yes KillMode=process Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target 重启flannel和docker： # systemctl daemon-reload # systemctl start flanneld # systemctl enable flanneld # systemctl restart docker 检查是否生效： # ps -ef |grep docker root 20941 1 1 Jun28 ? 09:15:34 /usr/bin/dockerd --bip=172.17.34.1/24 --ip-masq=false --mtu=1450 # ip addr 3607: flannel.1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UNKNOWN link/ether 8a:2e:3d:09:dd:82 brd ff:ff:ff:ff:ff:ff inet 172.17.34.0/32 scope global flannel.1 valid_lft forever preferred_lft forever 3608: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1450 qdisc noqueue state UP link/ether 02:42:31:8f:d3:02 brd ff:ff:ff:ff:ff:ff inet 172.17.34.1/24 brd 172.17.34.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:31ff:fe8f:d302/64 scope link valid_lft forever preferred_lft forever 确保docker0与flannel.1在同一网段,如果能通说明Flannel部署成功。 在Master节点部署组件 在部署Kubernetes之前一定要确保etcd、flannel、docker是正常工作的，否则先解决问题再继续。 生成证书 创建CA证书： # cat ca-config.json { &quot;signing&quot;: { &quot;default&quot;: { &quot;expiry&quot;: &quot;87600h&quot; }, &quot;profiles&quot;: { &quot;kubernetes&quot;: { &quot;expiry&quot;: &quot;87600h&quot;, &quot;usages&quot;: [ &quot;signing&quot;, &quot;key encipherment&quot;, &quot;server auth&quot;, &quot;client auth&quot; ] } } } } # cat ca-csr.json { &quot;CN&quot;: &quot;kubernetes&quot;, &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;Beijing&quot;, &quot;ST&quot;: &quot;Beijing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ] } # cfssl gencert -initca ca-csr.json | cfssljson -bare ca - 生成apiserver证书： # cat server-csr.json { &quot;CN&quot;: &quot;kubernetes&quot;, &quot;hosts&quot;: [ &quot;10.0.0.1&quot;, &quot;127.0.0.1&quot;, &quot;192.168.31.63&quot;, &quot;kubernetes&quot;, &quot;kubernetes.default&quot;, &quot;kubernetes.default.svc&quot;, &quot;kubernetes.default.svc.cluster&quot;, &quot;kubernetes.default.svc.cluster.local&quot; ], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ] } cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes server-csr.json | cfssljson -bare server 生成kube-proxy证书： # cat kube-proxy-csr.json { &quot;CN&quot;: &quot;system:kube-proxy&quot;, &quot;hosts&quot;: [], &quot;key&quot;: { &quot;algo&quot;: &quot;rsa&quot;, &quot;size&quot;: 2048 }, &quot;names&quot;: [ { &quot;C&quot;: &quot;CN&quot;, &quot;L&quot;: &quot;BeiJing&quot;, &quot;ST&quot;: &quot;BeiJing&quot;, &quot;O&quot;: &quot;k8s&quot;, &quot;OU&quot;: &quot;System&quot; } ] } # cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy 最终生成以下证书文件： # ls *pem ca-key.pem ca.pem kube-proxy-key.pem kube-proxy.pem server-key.pem server.pem 部署apiserver组件 下载二进制包：https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.12.md # mkdir /opt/kubernetes/{bin,cfg,ssl} -p # tar zxvf kubernetes-server-linux-amd64.tar.gz # cd kubernetes/server/bin # cp kube-apiserver kube-scheduler kube-controller-manager kubectl /opt/kubernetes/bin 创建token文件: # cat /opt/kubernetes/cfg/token.csv 674c457d4dcf2eefe4920d7dbb6b0ddc,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot; 创建apiserver配置文件： # cat /opt/kubernetes/cfg/kube-apiserver KUBE_APISERVER_OPTS=&quot;--logtostderr=true \\ --v=4 \\ --etcd-servers=https://192.168.31.63:2379,https://192.168.31.65:2379,https://192.168.31.66:2379 \\ --bind-address=192.168.31.63 \\ --secure-port=6443 \\ --advertise-address=192.168.31.63 \\ --allow-privileged=true \\ --service-cluster-ip-range=10.0.0.0/24 \\ --enable-admission-plugins=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota,NodeRestriction \\ --authorization-mode=RBAC,Node \\ --enable-bootstrap-token-auth \\ --token-auth-file=/opt/kubernetes/cfg/token.csv \\ --service-node-port-range=30000-50000 \\ --tls-cert-file=/opt/kubernetes/ssl/server.pem \\ --tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \\ --client-ca-file=/opt/kubernetes/ssl/ca.pem \\ --service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \\ --etcd-cafile=/opt/etcd/ssl/ca.pem \\ --etcd-certfile=/opt/etcd/ssl/server.pem \\ --etcd-keyfile=/opt/etcd/ssl/server-key.pem&quot; 配置好前面生成的证书，确保能连接etcd。 systemd管理apiserver： # cat /usr/lib/systemd/system/kube-apiserver.service [Unit] Description=Kubernetes API Server Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserver ExecStart=/opt/kubernetes/bin/kube-apiserver $KUBE_APISERVER_OPTS Restart=on-failure [Install] WantedBy=multi-user.target 启动： # systemctl daemon-reload # systemctl enable kube-apiserver # systemctl restart kube-apiserver 部署scheduler组件 创建schduler配置文件： # cat /opt/kubernetes/cfg/kube-scheduler KUBE_SCHEDULER_OPTS=&quot;--logtostderr=true \\ --v=4 \\ --master=127.0.0.1:8080 \\ --leader-elect&quot; systemd管理schduler组件： # cat /usr/lib/systemd/system/kube-scheduler.service [Unit] Description=Kubernetes Scheduler Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=-/opt/kubernetes/cfg/kube-scheduler ExecStart=/opt/kubernetes/bin/kube-scheduler $KUBE_SCHEDULER_OPTS Restart=on-failure [Install] WantedBy=multi-user.target 启动： # systemctl daemon-reload # systemctl enable kube-scheduler # systemctl restart kube-scheduler 部署controller-manager组件 创建controller-manager配置文件： # cat /opt/kubernetes/cfg/kube-controller-manager KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=true \\ --v=4 \\ --master=127.0.0.1:8080 \\ --leader-elect=true \\ --address=127.0.0.1 \\ --service-cluster-ip-range=10.0.0.0/24 \\ --cluster-name=kubernetes \\ --cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \\ --cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \\ --root-ca-file=/opt/kubernetes/ssl/ca.pem \\ --service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem&quot; systemd管理controller-manager组件： # cat /usr/lib/systemd/system/kube-controller-manager.service [Unit] Description=Kubernetes Controller Manager Documentation=https://github.com/kubernetes/kubernetes [Service] EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-manager ExecStart=/opt/kubernetes/bin/kube-controller-manager $KUBE_CONTROLLER_MANAGER_OPTS Restart=on-failure [Install] WantedBy=multi-user.target 启动： # systemctl daemon-reload # systemctl enable kube-controller-manager # systemctl restart kube-controller-manager 所有组件都已经启动成功，通过kubectl工具查看当前集群组件状态： # /opt/kubernetes/bin/kubectl get cs NAME STATUS MESSAGE ERROR scheduler Healthy ok etcd-0 Healthy {&quot;health&quot;:&quot;true&quot;} etcd-2 Healthy {&quot;health&quot;:&quot;true&quot;} etcd-1 Healthy {&quot;health&quot;:&quot;true&quot;} controller-manager Healthy ok 在Node节点部署组件 Master apiserver启用TLS认证后，Node节点kubelet组件想要加入集群，必须使用CA签发的有效证书才能与apiserver通信，当Node节点很多时，签署证书是一件很繁琐的事情，因此有了TLS Bootstrapping机制，kubelet会以一个低权限用户自动向apiserver申请证书，kubelet的证书由apiserver动态签署。 将kubelet-bootstrap用户绑定到系统集群角色 kubectl create clusterrolebinding kubelet-bootstrap \\ --clusterrole=system:node-bootstrapper \\ --user=kubelet-bootstrap 创建kubeconfig文件 在生成kubernetes证书的目录下执行以下命令生成kubeconfig文件： # 创建kubelet bootstrapping kubeconfig BOOTSTRAP_TOKEN=674c457d4dcf2eefe4920d7dbb6b0ddc KUBE_APISERVER=&quot;https://192.168.31.63:6443&quot; # 设置集群参数 kubectl config set-cluster kubernetes \\ --certificate-authority=./ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=bootstrap.kubeconfig # 设置客户端认证参数 kubectl config set-credentials kubelet-bootstrap \\ --token=${BOOTSTRAP_TOKEN} \\ --kubeconfig=bootstrap.kubeconfig # 设置上下文参数 kubectl config set-context default \\ --cluster=kubernetes \\ --user=kubelet-bootstrap \\ --kubeconfig=bootstrap.kubeconfig # 设置默认上下文 kubectl config use-context default --kubeconfig=bootstrap.kubeconfig #---------------------- # 创建kube-proxy kubeconfig文件 kubectl config set-cluster kubernetes \\ --certificate-authority=./ca.pem \\ --embed-certs=true \\ --server=${KUBE_APISERVER} \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-credentials kube-proxy \\ --client-certificate=./kube-proxy.pem \\ --client-key=./kube-proxy-key.pem \\ --embed-certs=true \\ --kubeconfig=kube-proxy.kubeconfig kubectl config set-context default \\ --cluster=kubernetes \\ --user=kube-proxy \\ --kubeconfig=kube-proxy.kubeconfig kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig 将这两个文件拷贝到Node节点/opt/kubernetes/cfg目录下: # ls bootstrap.kubeconfig kube-proxy.kubeconfig 部署kubelet组件 将前面下载的二进制包中的kubelet和kube-proxy拷贝到/opt/kubernetes/bin目录下。 创建kubelet配置文件： # cat /opt/kubernetes/cfg/kubelet KUBELET_OPTS=&quot;--logtostderr=true \\ --v=4 \\ --hostname-override=192.168.31.65 \\ --kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \\ --bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \\ --config=/opt/kubernetes/cfg/kubelet.config \\ --cert-dir=/opt/kubernetes/ssl \\ --pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0&quot; 其中/opt/kubernetes/cfg/kubelet.config配置文件如下： kind: KubeletConfiguration apiVersion: kubelet.config.k8s.io/v1beta1 address: 192.168.31.65 port: 10250 readOnlyPort: 10255 cgroupDriver: cgroupfs clusterDNS: [&quot;10.0.0.2&quot;] clusterDomain: cluster.local. failSwapOn: false authentication: anonymous: enabled: true systemd管理kubelet组件： # cat /usr/lib/systemd/system/kubelet.service [Unit] Description=Kubernetes Kubelet After=docker.service Requires=docker.service [Service] EnvironmentFile=/opt/kubernetes/cfg/kubelet ExecStart=/opt/kubernetes/bin/kubelet $KUBELET_OPTS Restart=on-failure KillMode=process [Install] WantedBy=multi-user.target 启动： # systemctl daemon-reload # systemctl enable kubelet # systemctl restart kubelet 在Master审批Node加入集群： 启动后还没加入到集群中，需要手动允许该节点才可以。 在Master节点查看请求签名的Node： # kubectl get csr # kubectl certificate approve XXXX # kubectl get node 部署kube-proxy组件 创建kube-proxy配置文件： # cat /opt/kubernetes/cfg/kube-proxy KUBE_PROXY_OPTS=&quot;--logtostderr=true \\ --v=4 \\ --hostname-override=192.168.31.65 \\ --cluster-cidr=10.0.0.0/24 \\ --kubeconfig=/opt/kubernetes/cfg/kube-proxy.kubeconfig&quot; systemd管理kube-proxy组件： # cat /usr/lib/systemd/system/kube-proxy.service [Unit] Description=Kubernetes Proxy After=network.target [Service] EnvironmentFile=-/opt/kubernetes/cfg/kube-proxy ExecStart=/opt/kubernetes/bin/kube-proxy $KUBE_PROXY_OPTS Restart=on-failure [Install] WantedBy=multi-user.target 启动： # systemctl daemon-reload # systemctl enable kube-proxy # systemctl restart kube-proxy 查看集群状态 # kubectl get node # kubectl run nginx --image=nginx --replicas=3 # kubectl expose deployment nginx --port=88 --target-port=80 --type=NodePort # kubectl get pods,svc ","link":"https://mzqk.github.io/post/er-jin-zhi-bu-shu-kubernetes-ji-qun/"},{"title":"如何阅读一本书","content":"如何阅读一本书 挑出阅读的层次说明 基础阅读层次 准备阅读阶段 认字阶段 读写阶段 基础阅读阶段 检视阅读层次 第一阶段：略读 先看书名页，然后如果有序就先看序。 研究目录页，对这本书的基本架构做概括性的理解。 如果书中附有索引，也要检阅一下。 如果那是本包着书衣的新书，不妨读一下出版者的介绍。 从你对一本书的目录很概略，甚至有点模糊的印象当中，开始挑几个看来跟主题息息相关的篇章来看。 最后一步，把书打开来，东翻翻西翻翻，念个一两段．有时候连续读几页，但不要太多。 第二阶段：粗浅阅读 头一次面对一本难读的书的时候，从头到尾先读完一遍，碰到不懂的地方不要停下来查询或思索。 提升阅读的速度： 将大拇指与食指、中指合并在一起，用这个“指针”顺着一行一行的字移动下去，速度要比你眼睛感觉的还要快一点。强迫自己的眼睛跟着手部的动作移动 。一旦你的眼睛能跟着手移动时，你就能读到那些字句了。 第三阶段：主动的基础阅读 一个阅读者要提出的四个基本问题 整体来说，这本书到底在谈些什么？ 作者细部说了什么，怎么说的？ 这本书说得有道理吗？ 这本书跟你有什么关系？ 第四阶段:做笔记 画底线—在主要的重点，或重要又有力量的句子下画线。 在画底线处的栏外再加画一道线—把你已经画线的部分再强调一遍，或是某一段很重要 ，但要画底线太长了，便在这一整段外加上一个记号。 在空白处做星号或其他符号—要慎用，只用来强调书中十来个最重要的声明或段落即可。你可能想要将做过这样记号的地方每页折一个角，或是夹一张书签，这样你随时从书架上拿起这本书，打开你做记号的地方，就能唤醒你的记忆。 在空白处 编号—作者的某个论点发展出一连串的重要陈述时，可以做顺序编号。 在空白处记下其他的页码—强调作者在书中其他部分也有过同样的论点，或相关 的要点，或是与此处观点不同的地方。这样做能让散布全书的想法统一集中起来。许多读者会用Cf这样的记号，表示比较或参照的意思。 将关键字或句子圈出来—这跟画底线是同样的功能。 在书页的空白处做笔记—在阅读某一章节时，你可能会有些问题（或答案），在空白处记下来，这样可以帮你回 想起你的问题或答案。你也可以将复杂的论点简化说明在书页的空白处。或是记下全书所有主要论点的发展顺序。书中最后一页可以用来作为个人的索引 页，将作者的主要观点依序记下来。 分析阅读层次 第一阶段：找出共通的词义 第一个规则 你一定要知道自己在读的是哪一类书，而且要越早知道越好。 第二个规则 使用一个单一的句子，或最多几句话（一小段文字）来叙述整本书的内容。 第三个规则 将书中重要篇章列举出来，说明它们如何按照顺序组成一个整体的架构。 根据第三个规则，可以有一套运用的公式。这个公式是可以通用的。根据第二个规则，我们可以说出这本书的内容是如此这般。做完这件事之后，我们可 以依照第三个规则，将内容大纲排列如下：(1)作者将全书分成五个部分，第一部分谈的是什么，第二部分谈的是什么，第三部分谈的是别的事，第四部分 则是另外的观点，第五部分又是另一些事。(2)第一个主要的部分又分成三个段落，第一段落为X，第二段落为Y，第三段落为Z。(3)在第一部分的第一阶段 ，作者有四个重点，第一个重点是A，第二个重点是B，第三个重点是C，第四个重点是D等等。 第四个规则 找出作者要问的问题。一本书的作者在开始写作时，都是有一个问题或一连串的问题，而这本书的内容就是一个答案，或许多答 案。 第二阶段：诠释一本书的内容 第一个规则 诠释作者使用的关键字，与作者达成共识。 第二个规则 从最重要的句子中 抓出作者的重要主旨。 第三个规则 从最重要的句子中 抓出作者的重要主旨。 第四个规则 )确定作者已经解决了哪些问题，还有哪些是未解决的 。在未解决的问题中，确定哪些是作者认为自己无法解决的问题。 主题阅读层次 ","link":"https://mzqk.github.io/post/ru-he-yue-du-yi-ben-shu/"},{"title":"时间管理-如何充分利用你的24小时","content":"时间管理-如何充分利用你的24小时 你目前如何利用时间 意识 了解你是如何使用时间的 检查自己的时间花销（时间日志、时间分类统计），意识到哪里的时间用的过多 确定目标建立行动路线图 规划时间，确定目标（短期目标、长期目标） 把你的任务写在工作清单上，把你的目标写在使命描述中。 任务：至最近某个时间你必须完成的一件杂务、差事或工作。 正确选择 在当下的满足与牺牲之间进行选择——你可以规划你的人生。而如果你不做出选择，你就只能任由其他力量主宰你的人生。 使你的时间发挥最大的效用 认识时间是有限的 合理匹配时间和精力 利用空隙时间 有效的时间管理减少时间浪费 迅速决策 快速阅读 提高记忆力 克服拖延 你不是你的思想。相反，你是在更高层次聆听你的思想。因此，你可以控制头脑中那些消极思想。 你可以采取的唯一脏鞥女奥的一个步骤是学会不认同自己的思想。有时你可以心中的某些想法一笑了之，把它们当做少不更事的小孩子荒诞不经的恶作剧。——《当下的力量》 当你把一种思想想象为一个物体时，你就可以控制它。你就可以一把拖延的想法驱逐出你的头脑，就像你将一只行为不端的猫赶出家门一样。——《思考与致富》 化繁为简（物品和思想） 《尽管去做：无压力工作的艺术》——大卫-艾伦 充分计划 每一个小时的计划抵得上五个小时的执行 分批处理 想办法多件事放在一起去完成，而不是单独去完成每一件事，以此来节约你的时间。 充分准备 通过提前进行思考和做好准备，你就可能减少为完成摆在你面前的任何任务所要付出的额努力。 制作任务清单 确定优先次序（四象限） 《高效能人士的七个习惯》——斯蒂芬-柯维 吃青蛙的原则是：如果你必须吃掉两只青蛙，那么，你要先吃较丑的那一只。——《吃掉那只青蛙》 高效率 假装忙碌使你没有时间进行自我反思 二八定律 一些活动会比另一些活动带来更大的回报；因此，要把大部分精力投入到那些真正能够给你带来“最大效益”的项目上去。 专注 不要同时处理多个任务，那是自欺欺人 后记 学会迅速丢弃且不内疚 立刻对事务做出决策 分类储存内容 指定时间回复 戴数显秒针的手表 随时记录心中想法 快速阅读 避免重复造轮子 限定时间完成任务 向前看抛弃过去 ","link":"https://mzqk.github.io/post/shi-jian-guan-li-ru-he-chong-fen-li-yong-ni-de-24-xiao-shi/"},{"title":"Xpath 基础使用","content":"XPath XPath语法 绝对路径 /html/body/tag /: 从根节点开始下选取 相对路径 //tag[@attibute='value']/tag 用法 说明 . 选取当前节点 .. 选取当前节点的父节点 @ 选取属性 [*] 选取节点下标 text() 选取文字 XPath轴 contains关键字 startwith关键字 查找父节点 查找平级节点 XPath运算符 | and or ","link":"https://mzqk.github.io/post/xpath-ji-chu-shi-yong/"},{"title":"搭建 SS 服务器","content":"搭建ss服务器 选择VPS Vultr 本人目前正在使用 Vultr全球最大的游戏主机提供商之一，使用它的原因主要是它是按小时计费的,价格也便宜。目前2.5美元每月的已经售完，5美元的每个月也有1T流量。 BandwagonHos BandwagonHost俗称搬瓦工,性价比很高。这种服务就是只拿来给新手学习Linux，我觉得也是很划得来。 阿里云 阿里云的产品在国内可以说是最好的云主机厂商之一。优点是相比外国的服务肯定要稳定些，但有一点不好就是建的网站无论大小都需要备案。 选择服务器节点 这里需要申明在国外购买的服务分配给的IP有一定可能会被墙掉，特别是我在Vultr上建的几个东京的站点无一能远程上（可能是人品问题）。 网络这方面大家可以自己ping通下，一般延时在200ms左右就能流畅使用。 选择操作系统 这里没什么好说的，建议选择Centos或Debian。这两个操作系统对今后的学习linux是很有好处的。 搭建Shadowsocks 这处便是本文关键 连接服务器 Windows用户建议下载Xshell 、MAC下可直接ssh连接。 下载Shadowsocks #安装python2.7及以上版本， yum install m2crypto python-setuptools easy_install pip pip install shadowsocks 配置 /etc/shadowsocks.json { &quot;server&quot;: &quot;192.0.0.1&quot;, &quot;server_port&quot;:8388, &quot;local_address&quot;: &quot;127.0.0.1&quot;, &quot;local_port&quot;:1080, &quot;password&quot;: &quot;12345678&quot;, &quot;timeout&quot;:300, &quot;method&quot;: &quot;aes-256-cfb&quot; } #也可配置多端口(记住要检查相应端口是否开启) 具体配置 yum install git git clone https://github.com/shadowsocks/shadowsocks.git 运行服务 #检查防火墙信息 firewall-cmd --query-port=443/tcp firewall-cmd --zone=public --add-port=443/tcp --permanent firewall-cmd --reload #开启ss服务 ssserver -c /etc/shadowsocks.json -d start 简易防护 搭建云主机最重要的隐患就是恶意的网络攻击和厂商的抽风，搭建自行搜索保护服务器的方法（如关闭服务器的root远程登录），然后注意的就是利用网站的服务或则其他功能进行备份。 加速 两种加速代码均代理在github上，可在项目中查看详细信息。 锐速 https://github.com/91yun/serverspeeder BBR https://github.com/teddysun/across 下载相应客户端 https://github.com/shadowsocks ","link":"https://mzqk.github.io/post/da-jian-ss-fu-wu-qi/"},{"title":"RHCSA 基本考纲","content":"1.修改root密码 重启进入grub按e编辑 添加rd.break console=stty0 或者修改rw init=/sysroot/bin 进入修复模式 挂载根系统 mount -o remount.rw /sysroot 切换根目录 chroot /sysroot 修改root密码passwd 重建SELinux安全策略 touch /.autorelabel 退出重启 2.修改本机网络信息 修改主机名 /etc/sysconfig/network HOSTNAME信息 /etc/sysconfig/network localhost信息 或 hostnamectl set-hostname example.hostname 修改静态网卡信息 /etc/sysconfig/network-scripts/ifcfg-eth0 BOOTPROTO=static DNS1= IPADDR= NETMASK= GETWAY= 或 nm-connection-editor图形化界面 nmcli connection up &quot;System eth0&quot; 3.搭建默认软件仓库 yum-config-manager --add http://example.com 修改 /etc/yum.repos.d/example.repo 关闭KEY检查gpgcheck=0 yum clean all yum repolist 4.创建账户 创建用户组 groupadd adminuser 创建用户 useradd -G admin1 adminuser 创建用户不赋予shell交互 useradd -s /sbin/nologin admin2 设置用户密码 passwd admin1 5.配置文件权限 6.创建定时任务 开启cron服务 给admin1用户编辑一个任务 crontab -e -u admin1 7.创建共享目录 创建目录 mkdir /home/admin 给予用户组adminuser目录所有权 chown :adminuser /home/admin 赋予组内用户可读、可写和可执行权限，其他用户无权限 chmod 770 /home/admin 8.安装升级内核 下载内核 wget http://kernel.com/download/kernel.rpm 安装rpm包 rpm -ivh kernel.rpm 重启后确认内核版本 uname -r ","link":"https://mzqk.github.io/post/rhcsa-ji-ben-kao-gang/"},{"title":"简单监控windows服务批处理脚本","content":"@echo off rem 定义循环间隔时间和监测的服务： set secs=6000 set srvname=&quot;Redis&quot; echo. echo ======================================== echo == 查询计算机服务的状态， == echo == 每间隔%secs%秒种进行一次查询， == echo == 如发现其停止，则立即启动。 == echo ======================================== echo. echo 此脚本监测的服务是：%srvname% echo. if %srvname%. == . goto end :chkit set svrst=0 for /F &quot;tokens=1* delims= &quot; %%a in ('net start') do if /I &quot;%%a %%b&quot; == %srvname% set svrst=1 if %svrst% == 0 net start %srvname% set svrst= rem 下面的命令用于延时，否则可能会导致cpu单个核心满载。 ping -n %secs% 127.0.0.1 &gt; nul goto chkit :end ","link":"https://mzqk.github.io/post/jian-dan-jian-kong-windows-fu-wu-pi-chu-li-jiao-ben/"},{"title":"linux文件无法删除处理","content":"文件能够通过ls命令查看，但是却不能做修改 文件存在隐藏属性 通过lsattr查看文件属性，再用chattr命令去除特殊属性 通过磁盘inode查找文件 ls -i 查看文件inode节点 通过节点找出文件，并做其它操作 find . -inum 94251 -exec rm -f {} ; ","link":"https://mzqk.github.io/post/linux-wen-jian-wu-fa-shan-chu-chu-li/"},{"title":"execl合并多表宏","content":"Sub 合并当前目录下所有工作簿的全部工作表() Dim MyPath, MyName, AWbName Dim Wb As Workbook, WbN As String Dim G As Long Dim Num As Long Dim BOX As String Application.ScreenUpdating = False MyPath = ActiveWorkbook.Path MyName = Dir(MyPath &amp; &quot;\\&quot; &amp; &quot;*.xls&quot;) AWbName = ActiveWorkbook.Name Num = 0 Do While MyName &lt;&gt; &quot;&quot; If MyName &lt;&gt; AWbName Then Set Wb = Workbooks.Open(MyPath &amp; &quot;\\&quot; &amp; MyName) Num = Num + 1 With Workbooks(1).ActiveSheet .Cells(.Range(&quot;B65536&quot;).End(xlUp).Row + 2, 1) = Left(MyName, Len(MyName) - 4) For G = 1 To Sheets.Count Wb.Sheets(G).UsedRange.Copy .Cells(.Range(&quot;B65536&quot;).End(xlUp).Row + 1, 1) Next WbN = WbN &amp; Chr(13) &amp; Wb.Name Wb.Close False End With End If MyName = Dir Loop Range(&quot;B1&quot;).Select Application.ScreenUpdating = True MsgBox &quot;共合并了&quot; &amp; Num &amp; &quot;个工作薄下的全部工作表。如下：&quot; &amp; Chr(13) &amp; WbN, vbInformation, &quot;提示&quot; End Sub ","link":"https://mzqk.github.io/post/execl-he-bing-duo-biao-hong/"},{"title":"使用修改 hosts 文件方法访问外国网络","content":"hosts下载地址 首先科普下我们为什么不能访问Google、Twitter、Facebook 之类的网站 这是因为我们国家有GFW（英文名称Great Firewall of China）， 也称中国防火墙或中国国家防火墙的存在。为什么要有这个东西的 存在呢？对外的说法是保护国内的网络纯净和谐地发展道路,顺带养 活下国内的BAT ╮(￣⊿￣)╭我想GFW的存在意义是保护的是外国友人不被国内傻逼打扰•̀.̫•́✧ 为了方便用户记忆，我们将IP变成一个个的域名来输入到浏览器进行访问。而这使得访问网站时要先将其域名解析成 IP。DNS的作用就是进行IP解析，把域名对应到IP。 在GFW的五种封锁方法中，有一种简单而效果很好的方法是DNS污染。GFW会对DNS的解析过程进行干扰，这会使对某些被干扰的域名返回一个错误的IP地址给你的主机，使你无法正确连接到你要的服务器上读取正确的信息。Hosts 文件本来是用来提高解析效率。在进行 DNS请求以前，系统会先检查自己的Hosts文件中是否有这个地址映射关系，如果有则调用这个IP地址映射，如果没有再向已知的 DNS 服务器提出域名解析。也就是说 Hosts 的请求级别比 DNS 高。当你的Hosts 文件里面有对应的 IP 时，它就会直接访问那个 IP，而不用通过 DNS。所以，当我们直接将Google、Twitter、Facebook 之类的 IP 放入 Hosts 文件后，就可以跳过 DNS的解析这一步，直接就行IP访问，不受 GFW 的 DNS污染干扰了。 通俗易懂的说修改host后就能访问Google、Twitter、Facebook等被墙网站。 下面就来介绍修改hosts文件的方法 windows 修改文件需要管理员权限 找到文件目录C:\\Windows\\System32\\drivers\\etc\\hosts 把下载好的hosts文件全部内容复制到C:\\WINDOWS\\system32\\drivers\\etc目录中的hosts文件中 保存后在重启浏览器输入https://www.google.com.hk看是否能访问 如果还不可以访问在CMD窗口输入ipconfig /flushdns使其生效。 Linux and Mac Linux与Mac的hosts文件都在相同的目录下 /etc/hosts 同样是用下载好的hosts替代原有的文件 Mac终端输入sudo killall -HUP mDNSResponder使其生效。 Linux终端输入sudo systemctl restart NetworkManager。 注意 : 非systemd发行版，终端输入sudo rcnscd restart，如果不清楚请两个都试一次。 Android 我们知道Android也是Linux系统中的一种，但其修改办法还是有些许不同 需要获取root权限 文件所在路径/system/etc/hosts 补充一下： 就是为什么 Hosts的IP要时不时更改，为什么 FB、Twitter 会仍旧上不去。是因为 GFW 的第二个大招，IP 封锁。比如访问国外一个 IP 无法访问，Ping 不通，tracert 这个 IP 后发现，全部在边缘路由器 (GFW) 附近被拦截。换言之，GFW 直接拦截带有这个 IP 头的数据包。所以，如果你更改的 IP 被封锁了，就算你过了 DNS 这一关，也仍旧不能翻过GFW。而有些站，是直接被屏蔽，无论你怎么添加HOSTS都是不行的。 ","link":"https://mzqk.github.io/post/shi-yong-xiu-gai-hosts-wen-jian-fang-fa-fang-wen-wai-guo-wang-luo/"},{"title":"微信使用 Itchat 实现机器人自动回复功能","content":"itchat itchat是一个开源的微信个人号接口，使用python调用微信从未如此简单。 使用不到三十行的代码，你就可以完成一个能够处理所有信息的微信机器人。 当然，该api的使用远不止一个机器人，更多的功能等着你来发现 该接口与公众号接口itchat 共享类似的操作方式，学习一次掌握两个工具。 如今微信已经成为了个人社交的很大一部分，希望这个项目能够帮助你扩展你的个人的微信号、方便自己的生活。 安装 可以通过本命令安装itchat： pip install itchat 简单入门实例 有了itchat，如果你想要给文件传输助手发一条信息，只需要这样： import itchat itchat.auto_login() itchat.send('Hello, filehelper', toUserName='filehelper') 如果你想要回复发给自己的文本消息，只需要这样： import itchat @itchat.msg_register(itchat.content.TEXT) def text_reply(msg): return msg.text itchat.auto_login() itchat.run() 进阶应用 特殊的字典使用方式 通过打印itchat的用户以及注册消息的参数，可以发现这些值都是字典。 但实际上itchat精心构造了相应的消息、用户、群聊、公众号类。 其所有的键值都可以通过这一方式访问： @itchat.msg_register(TEXT) def _(msg): # equals to print(msg['FromUserName']) print(msg.fromUserName) 属性名为键值首字母小写后的内容。 author = itchat.search_friends(nickName='LittleCoder')[0] author.send('greeting, littlecoder!') 各类型消息的注册 通过如下代码，微信已经可以就日常的各种信息进行获取与回复。 import itchat, time from itchat.content import * @itchat.msg_register([TEXT, MAP, CARD, NOTE, SHARING]) def text_reply(msg): msg.user.send('%s: %s' % (msg.type, msg.text)) @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): msg.download(msg.fileName) typeSymbol = { PICTURE: 'img', VIDEO: 'vid', }.get(msg.type, 'fil') return '@%s@%s' % (typeSymbol, msg.fileName) @itchat.msg_register(FRIENDS) def add_friend(msg): msg.user.verify() msg.user.send('Nice to meet you!') @itchat.msg_register(TEXT, isGroupChat=True) def text_reply(msg): if msg.isAt: msg.user.send(u'@%s\\u2005I received: %s' % ( msg.actualNickName, msg.text)) itchat.auto_login(True) itchat.run(True) 命令行二维码 通过以下命令可以在登陆的时候使用命令行显示二维码： itchat.auto_login(enableCmdQR=True) 部分系统可能字幅宽度有出入，可以通过将enableCmdQR赋值为特定的倍数进行调整： # 如部分的linux系统，块字符的宽度为一个字符（正常应为两字符），故赋值为2 itchat.auto_login(enableCmdQR=2) 默认控制台背景色为暗色（黑色），若背景色为浅色（白色），可以将enableCmdQR赋值为负值： itchat.auto_login(enableCmdQR=-1) 退出程序后暂存登陆状态 通过如下命令登陆，即使程序关闭，一定时间内重新开启也可以不用重新扫码。 itchat.auto_login(hotReload=True) 用户搜索 使用search_friends方法可以搜索用户，有四种搜索方式： 仅获取自己的用户信息 获取特定UserName的用户信息 获取备注、微信号、昵称中的任何一项等于name键值的用户 获取备注、微信号、昵称分别等于相应键值的用户 其中三、四项可以一同使用，下面是示例程序： # 获取自己的用户信息，返回自己的属性字典 itchat.search_friends() # 获取特定UserName的用户信息 itchat.search_friends(userName='@abcdefg1234567') # 获取任何一项等于name键值的用户 itchat.search_friends(name='littlecodersh') # 获取分别对应相应键值的用户 itchat.search_friends(wechatAccount='littlecodersh') # 三、四项功能可以一同使用 itchat.search_friends(name='LittleCoder机器人', wechatAccount='littlecodersh') 关于公众号、群聊的获取与搜索在文档中有更加详细的介绍。 附件的下载与发送 itchat的附件下载方法存储在msg的Text键中。 发送的文件的文件名（图片给出的默认文件名）都存储在msg的FileName键中。 下载方法接受一个可用的位置参数（包括文件名），并将文件相应的存储。 @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): msg.download(msg.fileName) itchat.send('@%s@%s' % ( 'img' if msg['Type'] == 'Picture' else 'fil', msg['FileName']), msg['FromUserName']) return '%s received' % msg['Type'] 如果你不需要下载到本地，仅想要读取二进制串进行进一步处理可以不传入参数，方法将会返回图片的二进制串。 @itchat.msg_register([PICTURE, RECORDING, ATTACHMENT, VIDEO]) def download_files(msg): with open(msg.fileName, 'wb') as f: f.write(msg.download()) 用户多开 使用如下命令可以完成多开的操作： import itchat newInstance = itchat.new_instance() newInstance.auto_login(hotReload=True, statusStorageDir='newInstance.pkl') @newInstance.msg_register(itchat.content.TEXT) def reply(msg): return msg.text newInstance.run() 退出及登陆完成后调用特定方法 登陆完成后的方法需要赋值在loginCallback中。 而退出后的方法需要赋值在exitCallback中。 import time import itchat def lc(): print('finish login') def ec(): print('exit') itchat.auto_login(loginCallback=lc, exitCallback=ec) time.sleep(3) itchat.logout() 若不设置loginCallback的值，则将会自动删除二维码图片并清空命令行显示。 常见问题与解答 Q: 为什么中文的文件没有办法上传？ A: 这是由于requests的编码问题导致的。若需要支持中文文件传输，将[fields.py]fields.py-2文件放入requests包的packages/urllib3下即可 Q: 如何通过这个包将自己的微信号变为控制器？ A: 有两种方式：发送、接受自己UserName的消息；发送接收文件传输助手（filehelper）的消息 Q: 为什么我发送信息的时候部分信息没有成功发出来？ A: 有些账号是天生无法给自己的账号发送信息的，建议使用filehelper代替。 ","link":"https://mzqk.github.io/post/wei-xin-shi-yong-itchat-shi-xian-ji-qi-ren-zi-dong-hui-fu-gong-neng/"},{"title":"基础正则表达式","content":"基础正则表达式 符号 说明 * 前一个字符匹配任意次数 . 匹配任意一个字符（除换行符） ^ 匹配行首 $ 匹配行尾 [] 匹配中括号中任意一个字符 [^] 匹配中括号中以外的任意一个字符 |转义字符 {n} 匹配一个字符n次 {n，} 匹配一个字符n次以上 {n，m} 匹配一个字符n至m次 ","link":"https://mzqk.github.io/post/ji-chu-zheng-ze-biao-da-shi/"},{"title":"FHS","content":"/ bin 一般用户使用到的命令，可作为单用户维护模式启用命令 boot 内核加载文件，开机会加载到 cache data dev 设备文件 etc 系统配置文件 home 用户目录 user .bashrc .profile .bash_history .bash_logout .vimrc lib 动态库和模块文件 lib64 支持64位的函数库 media 挂载设备 mnt 临时挂载设备 opt 第三方软件 proc 虚拟文件系统，存放系统核心、行程信息（process）、周边设备等至内存 root 管理员目录 .bashrc .bash_history .profile .viminfo run 开机所产生的各项信息 sbin 系统命令，root所有权限 snap srv 服务进程所需数据文件 sys 虚拟文件系统，记录核心与系统硬件信息较相关的信息 tmp 临时目录 usr 官方软件 var 变量文件 ","link":"https://mzqk.github.io/post/fhs/"},{"title":"Python 基础知识","content":"本文仅为粗略地概括python编程的基本语法，若你有C二级的水平将可以轻易看懂。作为引导很容易了解到python基础，详细的最好能通过官方文档学习。 Python 源程序编码 除去第一行需要添加运行环境#!/usr/local/bin/python2还需要说明编码方式以使程序能够识别中文输出 # -*- coding: utf-8 -*- 数据结构 python的数据类型不需要像C一样特别声明 布尔值 True False 支持and、or和not运算 常量 常量常用全部大写指明，python的优雅在于有规定语法但却没有强制约束，你仍可以对常量做改变 PI = 3.14159265359 列表 list是一种有序的集合，可以随时添加和删除其中的元素。 list = [a,b,c,d] 元组 tuple和list非常类似，但是tuple一旦初始化就不能修改 tupe = ('a','b','c','b') 集合 set和dict类似，也是一组key的集合，但不存储value。由于key不能重复，所以，在set中，没有重复的key。 set = {'a','b','c','d'} 字典 dict全称dictionary，在其他语言中也称为map，使用键-值（key-value）存储，具有极快的查找速度。 dict = {'a':1,'b':2,'c':3,'d':4 } 特性 切片 取一个list或tuple的部分元素是非常常见的操作 L = list(range(100)) [L[0], L[1], L[2]] L[:10] L[-10:] L[10:20] L[:10:2] L[::5] [0,1,2] [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] [90, 91, 92, 93, 94, 95, 96, 97, 98, 99] [10, 11, 12, 13, 14, 15, 16, 17, 18, 19] [0, 2, 4, 6, 8] [0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95] 迭代 如果给定一个list或tuple，我们可以通过for循环来遍历这个list或tuple，这种遍历我们称为迭代（Iteration）。 因为dict的存储不是按照list的方式顺序排列，所以，迭代出的结果顺序很可能不一样。默认情况下，dict迭代的是key 列表生成器 列表生成式即ListComprehensions，是Python内置的非常简单却强大的可以用来创建list的生成式。 [x * x for x in range(1, 11)] [x * x for x in range(1, 11) if x % 2 == 0] [m + n for m in 'ABC' for n in 'XYZ'] [1, 4, 9, 16, 25, 36, 49, 64, 81, 100] [4, 16, 36, 64, 100] ['AX', 'AY', 'AZ', 'BX', 'BY', 'BZ', 'CX', 'CY', 'CZ'] 生成器 在Python中，列表在循环的过程中不断推算出后续的元素,这种一边循环一边计算的机制，称为生成器：generator。 g = (x * x for x in range(10)) #通过next()函数可依次调用元素的值 #同样可以使用循环的方式迭代出 迭代器 迭代器是一个可以记住遍历的位置的对象。迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 控制流程 if if x &lt; 0: print (小于零) elif x == 0: print (等于零) elif x == 1: prin(等于1) else: print(大于零) if判断语句可结合elif用来替换‘case’或‘switch’语句 for 常用遍历 a=['a','b','c','d'] for i in range(len(a)) print (i,a[i]) while value = raw_input('Please input a number:' ) while: if value &lt; 100: print 'Right' else: print 'Please input again' break、continue和else 从C语言引用过来，用在控制语句中跳出或延续 pass 表示什么都不做，可用来构建最小类。（另外也可以用来当作占位符） class myclass: pass 函数 函数嘛，基本编程语言都离不开它。函数能提高应用的模块性，和单一功能功能代码的重复利用率。我们在程序中很多语法本就个内建的函数，比如print()。 内建函数 Python内置了很多有用的函数，我们可以直接调用。 定义函数 def printNum(number): &quot;&quot;&quot; 这是函数 使用print.__doc__可以将其打印出 &quot;&quot;&quot; num = int(number) print(num) 装饰器 递归函数 在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。 通过定义的函数，我们将printNum函数定义为只打整数的print。 闭包 匿名函数 所谓匿名，意即不再使用 def 语句这样标准的形式定义一个函数 f = lambda x,y:x*y print f(4,5) #结果为4*5 装饰器 错误和异常 错误 我们说的错误指的是语法错误，也可以称作解析错误 异常 指的是在语法正常的情况下，表达式引发的错误。程序并不会因为其而崩溃，而是将这种异常的以报错的方式显示出来。既然我们知道了有异常一说（而且很多时候是无法避免的），那我们就该来处理这些异常。 while Ture: try: x = int(input(&quot;Please enter a number&quot;)) break except ValueError: print(&quot;That was no vaild number!Please try again&quot;) 基本语法如上 我们需要输入一个整数，但是如果你要输入的不是整数会怎样？这时候就会提示错误（异常），而且提示如上就是ValueError。这里我们自行定义异常的提示结果。 异常处理 由此我们就可以明白异常产生的一个原因，并且可以自行定义异常产生后处理。 那如果我们不知道程序会出现怎样的错误的该如何？这时就可以直接使用expect来将其异常归纳起来统一处理。在expect下加入else则表示没有异常就执行else后的程序块。 抛出异常 为什么我们要抛出异常呢？ 因为错误是class，捕获一个错误就是捕获到该class的一个实例。因此，错误并不是凭空产生的，而是有意创建并抛出的。Python的内置函数会抛出很多类型的错误，我们自己编写的函数也可以抛出错误。 自定义异常 异常出现我们可以做自定义，通过创建新的异常except Error as e：来命名自己的异常。 异常清理行为 最后来说的是异常的清理行为。假如我们在open了文件后出现异常导致没有close上文件，这样会引发一些不必要的问题。那么我们可以用try...finally来保证finally后的程序块必须执行，当然还有一种方法用with来代替try这是预定义的清理行为。 类 这是一个较麻烦的问题，但对于学过面向对象编程的人来说就较容易理解了。 附录 编码风格 关于缩进符官网介绍的有三种，一个制表符、两个空格或者四个空格。注意这三种风格绝不能混用 当然大多数人建议的尽量使用其中一种风格，并且长期使用它。而我的建议是我们就只把四个空格当作缩进符，因为Tab键存在平台之间的差异，虽然有时使用四个空格很是麻烦（那是因为你没有用到一款好的文本编辑器）。 命名规则 Python命名规则和大多数编程语言一样包含着数字、字母、下划线。（同样的首字符不能为数字） 这里的命名规则并没有强制要求，你也可以灵活使用。 （比如整个项目中并没有使用多少全局变量的时候你就可以将其全部大写） 关于变量 全使用小写字母，碰到多个单词合并成一个变量的时候可以使用_分隔 关于函数 尽量小写，碰到多个单词合并的时候其后接单词使用大写 关于类 首字母大写，多个单词合成时同函数的命名规则 ","link":"https://mzqk.github.io/post/python-ji-chu-zhi-shi/"},{"title":"Oracle 常用操作","content":"Oracle 删除重复数据只留一条 查找表中多余的重复记录，重复记录是根据单个字段（Id）来判断 select * from 表 where Id in (select Id from 表 group byId having count(Id) &gt;1 删除表中多余的重复记录，重复记录是根据单个字段（Id）来判断，只留有rowid最小的记录 DELETE from 表 WHERE (id) IN ( SELECT id FROM 表 GROUP BY id HAVING COUNT(id) &gt; 1) AND ROWID NOT IN (SELECT MIN(ROWID) FROM 表 GROUP BY id HAVING COUNT(*) &gt; 1); 查找表中多余的重复记录（多个字段） select * from 表 a where (a.Id,a.seq) in(select Id,seq from 表 group by Id,seq having count(*) &gt; 1) 删除表中多余的重复记录（多个字段），只留有rowid最小的记录 delete from 表 a where (a.Id,a.seq) in (select Id,seq from 表 group by Id,seq having count(*) &gt; 1) and rowid not in (select min(rowid) from 表 group by Id,seq having count(*)&gt;1) 查找表中多余的重复记录（多个字段），不包含rowid最小的记录 select * from 表 a where (a.Id,a.seq) in (select Id,seq from 表 group by Id,seq having count(*) &gt; 1) and rowid not in (select min(rowid) from 表 group by Id,seq having count(*)&gt;1) 例子 delete --select * from cell where cgi in (select cgi from cell group by cgi having count(cgi) &gt; 1) and time_stamp not in (select min(time_stamp) from cell group by cgi having count(cgi)&gt;1) 查看UNDO空间的快照 select s.username, u.name from v$transaction t,v$rollstat r, v$rollname u,v$session s where s.taddr=t.addr and t.xidusn=r.usn and r.usn=u.usn order by s.username; 查看正在进行的会话 SELECT b.sid oracleID, b.username 登录Oracle用户名, b.serial#, spid 操作系统ID, paddr, sql_text 正在执行的SQL, b.machine 计算机名 FROM v$process a, v$session b, v$sqlarea c WHERE a.addr = b.paddr AND b.sql_hash_value = c.hash_value 锁表和删除会话 select p.spid, a.serial#, c.object_name, b.session_id, b.oracle_username, b.os_user_name from v$process p, v$session a, v$locked_object b, all_objects c where p.addr = a.paddr and a.process = b.process and c.object_id = b.object_id ; select l.session_id,o.owner,o.object_name from v$locked_object l,dba_objects o where l.object_id=o.object_id; select t2.username,t2.sid,t2.serial#,t2.logon_time from v$locked_object t1,v$session t where t1.session_id=t2.sid order by t2.logon_time; alter system kill session '89,22763';session_id,serial# 索引失效 select index_name ,status from user_indexes where Status = 'UNUSABLE' select 'alter index ' || index_name || ' rebuild;' from user_indexes where Status = 'UNUSABLE' select owner, index_name,table_name from dba_indexes where status = 'UNUSABLE' select index_owner,index_Name,partition_name from dba_ind_partitions where status = 'UNUSABLE'; 新建用户 select * from dba_users create user fast_nokia identified by fast_nokia grant select any dictionary to fast_nokia grant connect,select any table to fast_nokia Oracle表空间增加数据文件 查看每个表空间当前数据文件剩余块 select * from dba_data_files where tablespace_name='TPADBS06' select * from dba_temp_files 给表空间增加数据文件 ALTER TABLESPACE USERS ADD DATAFILe '+DGSTATIC/jxwydb/datafile/users21.dbf' SIZE 50M AUTOEXTEND ON NEXT 100M MAXSIZE 31G; ALTER TABLESPACE TPADBS05 ADD DATAFILe '+DGWARE/jxwydb/datafile/tpadbs05_24.dbf' SIZE 50M AUTOEXTEND ON NEXT 100M MAXSIZE 31G; Oracle自动摘除分片维护 分片维护表 select * from tab_partition_drop 作业调度时间（目前是5点运行） select job,what,last_date,next_date,failures,broken from dba_jobs Where schema_user='CAIKE'; select * from user_jobs where what='PROC_DROP_PATITION_SCRIPT; 表空间查询 查看单个表空间使用情况 SELECT TABLESPACE_NAME,SEGMENT_NAME,TO_CHAR(SUM(BYTES)/(1024*1024),'999G999D999') CNT_MB FROM DBA_EXTENTS WHERE OWNER='NIOSDB' AND SEGMENT_TYPE LIKE 'TABLE%' and TABLESPACE_NAME='NIOSDBS' GROUP BY TABLESPACE_NAME,SEGMENT_NAME; *查看所有表空间使用情况 SELECT TABLESPACE_NAME,MAX_M,COUNT_BLOCKS FREE_BLK_CNT,SUM_FREE_M,TO_CHAR(100 * SUM_FREE_M/SUM_M, '99.99')||'%' AS PCT_FREE FROM (SELECT TABLESPACE_NAME,SUM(BYTES)/1024/1024 AS SUM_M FROM DBA_DATA_FILES GROUP BY TABLESPACE_NAME), (SELECT TABLESPACE_NAME AS FS_TS_NAME,MAX(BYTES)/1024/1024 AS MAX_M,COUNT(BLOCKS) AS COUNT_BLOCKS,SUM(BYTES/1024/1024) AS SUM_FREE_M FROM DBA_FREE_SPACE GROUP BY TABLESPACE_NAME) WHERE TABLESPACE_NAME = FS_TS_NAME ORDER BY PCT_FREE 恢复表数据修改内容 create table backup_table as select * from source_table as of timestamp sysdate - 1/48 where title like '%测试%'; sysdate - 1/48 半个小时以内操作的 sysdate - 1/24 一个小时内操作的 ","link":"https://mzqk.github.io/post/oracle-chang-yong-cao-zuo/"},{"title":"导出 Oracle 报表","content":" 登入oracle sqlplus niosdb/Niosoptr@jxwydb 导入sql @/home/oracle/zqk/zhibiaocity.sql ql内添加分隔&gt;||','|| sqlplus niosdb/Niosoptr@jxwydb &lt;&lt;EOF @/home/oracle/zqk/zhibiaocity.sql EOF 添加表头 sed '1i\\ name1,name2,name2...' 1.csv&gt;2.csv 整合脚本 #!/bin/ksh cd /home/oracle/zqk/cellflow putfile=&quot;aaa.csv&quot; sqlplus niosdb/Niosoptr@jxwydb &lt;&lt;EOF @/home/oracle/zqk/cellflow/cellflow.sql EOF sed '1i\\ 时间（小时级),ECGI,CELLNAME,上行流量,下行流量' $putfile&gt;tmp.file putfile=&quot;cellflow0515.csv&quot; cp tmp.file $putfile rm tmp.file rm aaa.csv ","link":"https://mzqk.github.io/post/dao-chu-oracle-bao-biao/"},{"title":"AIX 安装 SVN","content":"yum源包地址 packages.lst http://www.oss4aix.org/download/RPMS/subversion/subversion-1.7.3-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/subversion/subversion-devel-1.7.3-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/subversion/mod_dav_svn-1.7.3-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr/apr-1.4.6-1.aix5.2.ppc.rpm http://www.oss4aix.org/download/RPMS/apr/apr-devel-1.4.6-1.aix5.2.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-db4-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-devel-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-freetds-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-gdbm-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-ldap-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-odbc-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/apr-util/apr-util-sqlite-1.4.1-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/expat/expat-2.0.1-3.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/expat/expat-devel-2.0.1-3.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/file/file-libs-5.05-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/gettext/gettext-0.17-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/gettext/gettext-devel-0.17-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/neon/neon-0.29.5-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/neon/neon-devel-0.29.5-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/sqlite/sqlite-3.7.9-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/zlib/zlib-1.2.6-1.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/pkg-config/pkg-config-0.25-2.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/readline/readline-6.2-3.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/db4/db4-4.7.25-2.aix5.1.ppc.rpm http://www.oss4aix.org/download/RPMS/openssl/openssl-0.9.8u-1.aix5.1.ppc.rpm 下载二进制包脚本 auto_wget.sh #!/bin/sh echo &quot;auto download some rpm packages from Internet begin...&quot; if [ ! -f packages.lst ]; then echo &quot;Error: file packages.lst not exist.&quot; exit -1 fi for FILENAME in `cat packages.lst` do echo &quot;download $FILENAME begin...&quot; wget $FILENAME echo &quot;download $FILENAME end...&quot; done echo &quot;done&quot; exit 0 自动安装软件包脚本 auto_install.sh #!/bin/sh echo &quot;auto install some rpm packages from Internet begin...&quot; if [ ! -f packages.lst ]; then echo &quot;Error: file packages.lst not exist.&quot; exit -1 fi for FILENAME in `awk -F&quot;/&quot; '{print $NF}' packages.lst'` do echo &quot;Installing $FILENAME begin...&quot; rpm -ivh $FILENAME --nodeps echo &quot;Installing $FILENAME end...&quot; done echo &quot;done&quot; exit 0 官网介绍所需依赖环境 配置文件 ","link":"https://mzqk.github.io/post/aix-an-zhuang-svn/"},{"title":"Linux 常用 shell 命令","content":" ls -d $(echo ${PATH//😕 }) &gt; /dev/null 显示PATH中失效的目录 ​​​​ awk -F ',' '{ x = x + $4 } END { print x }' test.csv 从CSV中计算列的总数 diff &lt;(wget -q -O - URL1) &lt;(wget -q -O - URL2) 比较两个远程的网页 ​​​​ :r! echo % 在vim中插入当前文件名 cat file | tee &gt;&gt; file 把文件内容贴到他自己的尾巴上(直接cat 不可以) for ARG in * ; do sudo -u USER 7z x -o&quot;$(echo ARG|sed &#039;s/\\(.*\\)\\..*/\\1/&#039;)&quot; &quot;ARG&quot; ; done 解压当前目录下的所有的压缩文件，各个压缩文件都解压在自己的目录中 ssh user@remote-host &quot;DISPLAY=:0.0 import -window root -format png -&quot;|display -format png - 远程截屏 date --date=yesterday +%Y%m%d 格式化另一个日期 ​​​​ history &gt; ~/history-save-$(date +%d-%m-%y-%T) 备份命令历史 for i in &quot;*.txt&quot;; do tar -c -v -z -f i.tar.gz&quot;i.tar.gz &quot;i.tar.gz&quot;i&quot; &amp;&amp; rm -v &quot;$i&quot;; done 压缩所有的txt cat file.txt | sendmail -F myname -f admin@mysite.com guest@guest.com 命令行发邮件 rm $( ls | egrep -v 'abc|\\s' ) 删除除了叫abc的文件 ​​​​ find /path/ -type f -exec grep -l '' {} ; | xargs sed -i -e 's%%%g' 查找并替换 ​​​​ sleep 3s &amp;&amp; espeak &quot;wake up, you bastard&quot; 2&gt;/dev/null 计时器的实现 tar tfz filename.tgz |xargs rm -Rf 撤销解压tar的方法 ​​​​ awk 'BEGIN{IGNORECASE=1;FS=&quot;|&quot;;RS=EOF} {print $2}' file.html 获取html文件中title名字 ​​​​ truncate -s 1M file 创建特定大小的文件 ​​​​ ls -I &quot;*.gz&quot; 反向ls (ls 除了 *.gz) ​​​​ setenforce 0 关闭 SE Linux ​​​​ cat video.avi.001 video.avi.002 video.avi.003 &gt;&gt; video.avi 合并小电影 ​​​​ find -printf '%u %g\\n' | sort | uniq 获取当前目录的文件权限列表 ​​​​ cat .ssh/id_dsa.pub | ssh elsewhere &quot;[ -d .ssh ] || mkdir .ssh ; cat &gt;&gt; .ssh/authorized_keys&quot; 妈妈再也不用担心我忘了ssh密码 ​​​​ git svn --authors-file=some-authors-file clone svn://address/of/svn/repo new-git-dir 导入/克隆一个svn仓库到git仓库 ​​​​ find ~/Desktop/ ( -regex './..' ) -print -exec rm -Rf {} ; 查找删除隐藏文件 ​​​​ cat ~/.viminfo | sed -n '/^:[0-9]+,([0-9]+|$)s/p' 看看今天vim中使用了多少regex ​​​​ echo -n &quot;string&quot; | md5sum - 生成md5 ​​​​ free -m | awk '/Swap/ {print $4}' 释放swap cp -p ls -l | awk '/Apr 14/ {print $NF}' /usr/users/backup_dir 查找特定时间戳的文件 ​​​​ convert *.jpg File_Output.pdf 合并jpg为pdf zmv '(.)(.*)' '${1//./_}$2' 将文件名中的 . 替换成 _ ls -1 /lib/modules 列出安装的 kernels ​​​​ find . -type f -name filename.exe -exec sed -i &quot;s/oldstring/oldstring/g&quot; {} +; 在任何跟'filename.exe'同名的文件中查找并替换目标字符串。 rm !(.foo|.bar|*.baz) Delete all files in a folder that don't match a certain file extension 删除一个目录下所有不匹配特定扩展名的文件 ​​​​ ssh user@remote &quot;tar cfp - /path/to/log/* | gzip&quot; &gt; local.tar.gz 远程压缩后写到本地 ​​​​ find . -mmin -60 -not -path &quot;svn&quot; -print|more 忽略SVN文件和文件夹，递归查找最近一小时内修改过的文件 ​​​​ apt-cache show pkgname | grep -i &quot;version:&quot; 查看包版本 ​​​​ du -s * | sort -nr | head 寻找大文件 ​​​​ lsof | grep pcm 列出正在播放声音的进程 ​​​​ grep 'model|MHz' /proc/cpuinfo |tail -n 2 查看cpu型号 ​​​​ export var1=ps -A | grep '[u]nique' | cut -d '?' -f 1; echo${var1/ /}; kill -9 $var1 在无法使用pidof和pgrep的情况下，杀死PID未知的进程 nocomments () { cat 1 | egrep -v &#039;^[[:space:]]*#|^[[:space:]]*|[1]*;' | sed '//d' | sed '//d'; } 去掉注释 ​​​​ while true ; do sleep 1 ; clear ; (netstat -tn | grep -P ':36089\\s+\\d') ; done 监控端口连接 ​​​​ find . -maxdepth 1 -empty -delete 清理大小为0的文件 ​​​​ while [ /bin/true ]; do OLD=$NEW; NEW=cat /proc/net/dev | grep eth0 | tr -s ' ' | cut -d' ' -f &quot;3 11&quot;; echo $NEW $OLD | awk '{printf(&quot;\\rin 监控 RT/TX ​​​​ for i in *.xml; do sed -i 's/foo/bar/g' &quot;$i&quot;; done 批量替换xml中关键字 sed -n '/^.{255}/!p' 清除多余255个字符的行 rar a -m0 &quot;${PWD##*/}.rar&quot; * 自动命名创建rar的包 ​​​​ read -sn 1 -p &quot;Press any key to continue...&quot; Shell版 Press Any Key to Continue for count in (seq21001);dosay&quot;(seq 2 1001); do say &quot;(seq21001);dosay&quot;count sheeps&quot;;sleep 2;done 催眠 lftp -u&lt;&gt; &lt;&gt; -e &quot;du -a;exit&quot; &gt; server-listing.txt 获取ftp的目录结构 ​​​​ for i in $(find . -mtime +30); do mv $i old/; done 移动30天前的文件到old文件夹 ( ( sleep 2h; your-command your-args ) &amp; ) 在后台2个小时后运行一个命令 grep [#] /etc/file.conf 清理文件中的注释 cat /dev/urandom | tr -dc A-Za-z0-9 | head -c 32 长密码 while t;doforiin‘seq130‘;dor=&quot;t; do for i in `seq 1 30`;do r=&quot;t;doforiin‘seq130‘;dor=&quot;[(RANDOMRANDOM % 2)]&quot;;h=&quot;RANDOM[($RANDOM % 4)]&quot;;if [ $h -eq 1 ]; then v=&quot;\\e[1m $r&quot;;else v=&quot;\\e[2m r&quot;;fi;v2=&quot;r&quot;;fi;v2=&quot;r&quot;;fi;v2=&quot;v2 $v&quot;;done;echo -e $v2;v2=&quot;&quot;;done; 黑客帝国 ​​​​ echo $(( RANDOM % 10 + 1 )) 生成 1 到 10 的随机数 ​​​​ ​​​​ function gbl() { git for-each-ref --sort=-committerdate --format=&#039;%(committerdate) %(authorname) %(refname)&#039; refs/remotes/origin/|grep -e &quot;.@&quot;|head -n 10; } 按作者列出git远程分支 ruby -e &quot;i=0;loop{puts ' '(29(Math.sin(i)/2+1))+'|'(29(Math.cos(i)/2+1)); i+=0.1}&quot; 显示一个波形图案 ​​​​ awk -F&quot;:&quot; '{ print 1 }&#039; /etc/passwd | while read UU ; do STATUS=(passwd -S ${UU} | grep locked 2&gt;/dev/null) ; if [[ ! -z ${STATUS} ]] ; then echo &quot;Account ${UU} is locked.&quot; ; fi ; done 查找某些特定帐户是否被锁住 ​​​​ man -t ls &gt; ls.ps &amp;&amp; pdf2ps ls.ps &amp;&amp; rm ls.ps 将man文档输出为pdf格式 ​​​​ ls * | sed -e 'p;s/foo/bar/' | xargs -n2 mv 用sed批量重命名文件 ​​​​ echo $(shuf -i 1-35 | head -n7 | sort -n) 帮你卖双色球(35选7) ​​​​ find . -type d | sed -e &quot;s/[-][/]*// |/g&quot; -e &quot;s/|([^ ])/|-\\1/&quot; 目录树 ​​​​ ​​​​ echo -e &quot;\\e[3$(( $RANDOM * 6 / 32767 + 1 ))mHello World!&quot; 随机颜色的字 nc -zw2 www.example.com 80 &amp;&amp; echo open 查看tcp端口是不是打开了 ​​​​ myrm(){ D=/tmp/$(date +%Y%m%d%H%M%S); mkdir -p D;mv&quot;D; mv &quot;D;mv&quot;@&quot; $D &amp;&amp; echo &quot;moved to $D ok&quot;; } 建立删除回收机制 UNIX2dos [-kn] oldfile newfile 转换为Linux格式 perl -e &quot;use POSIX qw(strftime); print strftime '%Y%m%d' , localtime( time()-36002430) &quot; perl获取时间 [:space:] ↩︎ ","link":"https://mzqk.github.io/post/linux-chang-yong-shell-ming-ling/"},{"title":"Vim 自定插件","content":"插件 Vundle 插件管理 git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/nerdtree 添加至vimrc &quot;Vundle插件管理 set nocompatible &quot; 去除VI一致性,必须要添加 filetype off &quot; 必须要添加 &quot; 设置包括vundle和初始化相关的runtime path set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &quot; 让vundle管理插件版本 Plugin 'VundleVim/Vundle.vim' &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;所有插件需要在下面这行上面 &quot;安装插件的方式可以使用本地、git及网络安装 &quot;示例 &quot;Plugin 'git://git.wincent.com/command-t.git' &quot;Plugin 'file:///home/gmarik/path/to/plugin' &quot;Plugin 'tpope/vim-fugitive' &quot;重名插件 &quot;Plugin 'rstacruz/sparkup', {'rtp': 'vim/'} call vundle#end() &quot; required filetype plugin indent on &quot; required &quot; 忽视插件改变缩进,可以使用以下替代: &quot;filetype plugin on &quot; 常用的命令 &quot; :PluginList - 列出所有已配置的插件 &quot; :PluginInstall - 安装插件,追加 `!` 用以更新或使用 :PluginUpdate &quot; :PluginSearch foo - 搜索 foo ; 追加 `!` 清除本地缓存 &quot; :PluginClean - 除未使用插件,需要确认; 追加 `!` 自动批准移除未使用插件 &quot; :h vundle 查看帮助 &quot; 将你自己对非插件片段放在这行之后 NerdTree 目录树 &quot; 设置NerdTree &quot;Plugin 'scrooloose/nerdtree' let NERDTreeWinPos='left' let NERDTreeWinSize=30 map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt; &quot;默认开启NERDTree &quot;autocmd VimEnter * NERDTree &quot;当打开 NERDTree 窗口时，自动显示 Bookmarks let NERDTreeShowBookmarks=1 &quot; 是否显示隐藏文件 let NERDTreeShowHidden=1 使用说明 ?: 快速帮助文档 o: 打开一个目录或者打开文件，创建的是buffer，也可以用来打开书签 go: 打开一个文件，但是光标仍然留在NERDTree，创建的是buffer t: 打开一个文件，创建的是Tab，对书签同样生效 T: 打开一个文件，但是光标仍然留在NERDTree，创建的是Tab，对书签同样生效 i: 水平分割创建文件的窗口，创建的是buffer gi: 水平分割创建文件的窗口，但是光标仍然留在NERDTree s: 垂直分割创建文件的窗口，创建的是buffer gs: 和gi，go类似 x: 收起当前打开的目录 X: 收起所有打开的目录 e: 以文件管理的方式打开选中的目录 D: 删除书签 P: 大写，跳转到当前根路径 p: 小写，跳转到光标所在的上一级路径 K: 跳转到第一个子路径 J: 跳转到最后一个子路径 &lt;C-j&gt;和&lt;C-k&gt;: 在同级目录和文件间移动，忽略子目录和子文件 C: 将根路径设置为光标所在的目录 u: 设置上级目录为根路径 U: 设置上级目录为跟路径，但是维持原来目录打开的状态 r: 刷新光标所在的目录 R: 刷新当前根路径 I: 显示或者不显示隐藏文件 f: 打开和关闭文件过滤器 q: 关闭NERDTree A: 全屏显示NERDTree，或者关闭全屏 .vimrc set fileencodings=utf-8,gbk set termencoding=utf-8 set encoding=utf-8 syntax on &quot;语法高亮 set nocompatible &quot;关闭vi兼容模式 set nu &quot;显示行号 set ruler &quot;打开状态栏标尺 set softtabstop=4 &quot;退格键删除4个空格 set tabstop=4 &quot;设置tab长度为 4 set nobackup &quot;覆盖文件不备份 set autochdir &quot;自动切换当前目录 set hlsearch &quot;搜索高亮 set magic &quot;设置魔术 set smartindent &quot;自动缩行 set backspace=indent,eol,start set laststatus=2 &quot;显示状态栏 set bg=dark &quot;暗色背景 &quot;history存储容量 set history=2000 &quot;检测文件类型，采用不同的缩进格式 filetype on filetype indent on set autoindent &quot;备份设置 &quot;set backup &quot;set backupext=.bak &quot;set backupdir=~/.bak/ &quot;突出显示 set cursorcolumn set cursorline &quot;设置退出显示的内容 set t_ti= t_te= &quot;显示状态栏内容 set ruler set showcmd set showmode &quot;搜索显示 set showmatch set hlsearch set ignorecase &quot;取消方向键 &quot;map &lt;Left&gt; &lt;Nop&gt; &quot;map &lt;Right&gt; &lt;Nop&gt; &quot;map &lt;Up&gt; &lt;Nop&gt; &quot;map &lt;Down&gt; &lt;Nop&gt; &quot;python文件设置 autocmd FileType python set tabstop=4 shiftwidth=4 expandtab ai func! DeleteTrailingWS() exe &quot;normal mz&quot; %s/\\s\\+$//ge exe &quot;normal `z&quot; endfunc autocmd BufWrite *.py :call DeleteTrailingWS() &quot;脚本文件加入文件头 autocmd BufNewFile *.sh,*.py `exec` &quot;:call SetTitle()&quot; func SetTitle() if &amp;filetype == 'python' call setline(1, &quot;\\#!/usr/bin/env python&quot;) call setline(2, &quot;\\# -*- encoding:utf-8 -*-&quot;) endif if &amp;filetype == 'sh' call setline(1, &quot;\\#!/usr/bin/sh&quot;) endif endfunc &quot;&lt;F2&gt;开关行号 function! HideNumber() if(&amp;relativenumber == &amp;number) set relativenumber! number! elseif(&amp;number) set number! else set relativenumber! endif set number? endfunc nnoremap &lt;F2&gt; :call HideNumber()&lt;CR&gt; &quot;===========================================================&quot; &quot; 设置pydiction &quot;===========================================================&quot; let g:pydiction_location='~/.vim/bundle/pydiction/complete-dict' &quot;菜单高度 let g:pydiction_menu_height = 3 &quot;===========================================================&quot; &quot; 设置NerdTree &quot;===========================================================&quot; &quot;设置目录树位置 let NERDTreeWinPos='left' let NERDTreeWinSize=30 &quot;&lt;F3&gt;开关目录树 map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt; &quot;默认开启NERDTree &quot;autocmd VimEnter * NERDTree &quot;当打开 NERDTree 窗口时，自动显示 Bookmarks let NERDTreeShowBookmarks=1 &quot; 是否显示隐藏文件 let NERDTreeShowHidden=1 &quot;设置&lt;F4&gt;保存文件 map &lt;F4&gt; :&lt;ESC&gt;:w&lt;CR&gt; &quot;===========================================================&quot; &quot;Vundle插件管理 &quot;===========================================================&quot; set nocompatible &quot; 去除VI一致性,必须要添加 filetype off &quot; 必须要添加 &quot; 设置包括vundle和初始化相关的runtime path set rtp+=~/.vim/bundle/Vundle.vim call vundle#begin() &quot; 让vundle管理插件版本 Plugin 'VundleVim/Vundle.vim' Plugin 'scrooloose/nerdtree' Plugin 'rkulla/pydiction' &quot; &quot; &quot; &quot; &quot; &quot; &quot; &quot;所有插件需要在下面这行上面 &quot;安装插件的方式可以使用本地、git及网络安装 &quot;示例 &quot;Plugin 'git://git.wincent.com/command-t.git' &quot;Plugin 'file:///home/gmarik/path/to/plugin' &quot;Plugin 'tpope/vim-fugitive' &quot;重名插件 &quot;Plugin 'rstacruz/sparkup', {'rtp': 'vim/'} call vundle#end() &quot; required filetype plugin indent on &quot; required &quot; 忽视插件改变缩进,可以使用以下替代: &quot;filetype plugin on ","link":"https://mzqk.github.io/post/vim-zi-ding-cha-jian/"},{"title":"Shell 教程基础教程","content":"变量 变量数组 var_name=(varlue0 value1 varlue2 varlue3) name[n]=varlue 只读变量 readonly=varlue 删除变量 unset var_nam 特殊变量 变量 含义 $0 当前脚本的文件名 $n 传递给脚本或函数的参数。n是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。 $# 传递给脚本或函数的参数个数。 $@ 传递给脚本或函数的所有参数。 $* 传递给脚本或函数的所有参数。被双引号(&quot;&quot;)包含时，与$@稍有不同。 $? 上个命令的退出状态，或函数的返回值。 $$ 当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 运算符 算数运算符 运算符 说明 举例 + 加法 expr $a + $b 结果为 30。 - 减法 expr $a - $b 结果为 -10。 * 乘法 expr $a \\* $b 结果为 200。 / 除法 expr $b / $a 结果为 2。 % 取余 expr $b % $a 结果为 0。 = 赋值 a=$b 将把变量 b 的值赋给 a。 == 相等 用于比较两个数字，相同则返回 true。 [ $a == $b ] 返回 false。 != 不相等 用于比较两个数字，不相同则返回 true。 [ $a != $b ] 返回 true。 关系运算符 运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ] 返回 false。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ] 返回 true。 逻辑运算符 运算符 说明 举例 &amp;&amp; 逻辑的 AND [[ $a -lt 100 &amp;&amp; $b -gt 100 ]] 返回 false ll 逻辑的 OR [[ $a -lt 100 ll $b -gt 100 ]] 返回 true 环境配置 流程控制 if分支 if [条件判断] ;then 条件执行 if case分支 case $变量 in &quot;变量1&quot;) command1 ;; &quot;变量2&quot;) command2 ;; *） exit 1 ；； esac for循环 常用语法 for $变量 in var do command done c语言语法 num=n for ((a=1;a &lt;= num; a+1 )) do comand done while循环 while [条件判断] do command done c语言语法 ((a=1)) num=n while ((a &lt;= num)) do command done until循环 until [条件判断] do command done select结构 PS3=' 设置提示符字串 ' select $变量 in var do command break done 函数 function funname () { command } ","link":"https://mzqk.github.io/post/shell-jiao-cheng-ji-chu-jiao-cheng/"},{"title":"Linux 常用命令","content":"awk awk语法 参数 说明 -F 以指定字符作为分割字段 awk用法 打印/etc/passwd内容 awk '{print}' /etc/passwd root❌0:0:root:/root:/bin/bash daemon❌1:1:daemon:/usr/sbin:/usr/sbin/nologin bin❌2:2:bin:/bin:/usr/sbin/nologin sys❌3:3:sys:/dev:/usr/sbin/nologin sync❌4:65534:sync:/bin:/bin/sync games❌5:60:games:/usr/games:/usr/sbin/nologin man❌6:12👨/var/cache/man:/usr/sbin/nologin lp❌7:7:lp:/var/spool/lpd:/usr/sbin/nologin mail❌8:8:mail:/var/mail:/usr/sbin/nologin news❌9:9:news:/var/spool/news:/usr/sbin/nologin uucp❌10:10:uucp:/var/spool/uucp:/usr/sbin/nologin proxy❌13:13:proxy:/bin:/usr/sbin/nologin www-data❌33:33:www-data:/var/www:/usr/sbin/nologin backup❌34:34:backup:/var/backups:/usr/sbin/nologin 以冒号为分隔符取1、3、6位内容 awk -F &quot;:&quot; '{print $1 $3 $6}' /etc/passwd bin2/bin sys3/dev sync4/bin games5/usr/games man6/var/cache/man lp7/var/spool/lpd mail8/var/mail news9/var/spool/news uucp10/var/spool/uucp proxy13/bin www-data33/var/www backup34/var/backups 取出内容以Tab建作为分隔符 awk -F &quot;:&quot; '{print $1 &quot;\\t&quot; $3 &quot;\\t&quot; $6}' /etc/passwd root 0 /root daemon 1 /usr/sbin bin 2 /bin sys 3 /dev sync 4 /bin games 5 /usr/games man 6 /var/cache/man lp 7 /var/spool/lpd mail 8 /var/mail news 9 /var/spool/news uucp 10 /var/spool/uucp proxy 13 /bin www-data 33 /var/www backup 34 /var/backups 内容加以排版 awk -F &quot;:&quot; '{print &quot;ID=&quot;$1 &quot;\\t 家目录=&quot;$6}' /etc/passwd ID=root 家目录=/root ID=daemon 家目录=/usr/sbin ID=bin 家目录=/bin ID=sys 家目录=/dev ID=sync 家目录=/bin ID=games 家目录=/usr/games ID=man 家目录=/var/cache/man ID=lp 家目录=/var/spool/lpd ID=mail 家目录=/var/mail ID=news 家目录=/var/spool/news ID=uucp 家目录=/var/spool/uucp ID=proxy 家目录=/bin ID=www-data 家目录=/var/www ID=backup 家目录=/var/backups crontab crontab语法 -l 列出定时任务列表 -e 编辑定时任务内容 -u 设定指定用户 crontab用法 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 cat chattr date find expr git Git 配置 添加git信息 git config --global user.name &quot;Scott Chacon&quot; git config --global user.email &quot;schacon@gmail.com&quot; # --global 为全局选项 git信息配置文件 ~/.gitconfig Git仓库 克隆一个项目 git clone https://github.com/MZqk/boco 初始化一个仓库 cd ./ git init Git流程 git add #添加新创建或修改的文件到本地的缓存区（Index） git rm #删除后会自动将已删除文件的信息添加到缓存区 git commit #命令提交到本地代码库 git status #查看当前git仓库的状态 git diff --cached #如果没有--cached参数，git diff 会显示当前你所有已做的但没有加入到索引里的修改 git push origin master #将本地仓库同步到远端服务器 分支与合并 git branch #查看当前的分支列表 git branch experimental #创建一个新的叫 experimental的分支 git checkout experimental #切换到experimental分支 git merge -m 'merge experimental branch' experimental #将experimental分支合并到当前分支 git branch -d experimental #只能删除那些已经被当前分支的合并的分支. 如果你要强制删除某个分支的话就用git branch –D git reset --hard HEAD^ #回到合并之前的状态 Git日志 git log #显示所有的提交 git log v2.5.. Makefile fs/ #找出所有从&quot;v2.5“开始在fs目录下的所有Makefile的修改 git log --stat 打印详细的提交记录 git log --pretty=oneline 格式化日志输出,可用medium,full,fuller,email 或raw git log --graph --pretty=oneline 可视化提交图 git log --pretty=format:'%h : %s' --topo-order --graph 提交按拓扑顺序来显示 grep sed sed语法 参数 说明 -n 显示处理后的过程，自动换行 sed用法 文件内容 line 1 This is a book line 2 That is a pen line 3 Happy Holiday line 4 Niscenter is a good place line 5 End 删除第2到4行内容 sed '2,4d' file line 1 This is a book line 5 End 替换每行第一个is为error sed 's/is/error/' file line 1 Therror is a book line 2 That error a pen line 3 Happy Holiday line 4 Nerrorcenter is a good place line 5 End 替换全部的is为error sed 's/is/error/g' file line 1 Therror error a book line 2 That error a pen line 3 Happy Holiday line 4 Nerrorcenter error a good place line 5 End 在有center内容的一行替换is为xx sed '/center/s/is/xx/g' file line 1 This is a book line 2 That is a pen line 3 Happy Holiday line 4 Nxxcenter xx a good place line 5 End tar tar语法 参数 说明 -c --crate 创建新的归档,即打包 -r --append 向压缩文件追加内容 -t --list 查看压缩全部的内容 -u --update 更新压缩文件 -x --extract 释放归档文件，即解压 -v 显示操作过程 -z 解压tar.gz、tgz文件选项 -j 解压tar.bz2文件 -f 制定压缩文件名 -C 切换至指定目录 --exclude file 压缩过程中排除指定文件 tar用法 tar tar -xvf filename.tar tar -cvf filename.tar dirname tar.gz tar -zxvf filename.tar.gz tar -zxcf filename.tar.gz dirname tar.bz2 tar -jxvf filename.tar.bz2 tar -jxcf filename.tar.bz2 dirname test test语法 参数 说明 -d 如果文件为一个目录，则为真 -e 如果文件存在，则为真 -G 如果文件存在且归该组所有，则为真 -O 如果文件存在并且归该用户所有，则为真 -s 如果文件的长度不为零，则为真 -r 如果文件可读，则为真 -w 如果文件可写，则为真 -x 如果文件可执行，则为真 -eq 数值等于,则为真 -ne 数值不等于,则为真 -gt 数值大于,则为真 -ge 数值小于等于,则为真 -lt 数值小于,则为真 -le 数值小于等于,则为真 = 字符相等，则为真 != 字符不相等，则为真 -z 字符串长度为零，则为真 -n 字符串长度不为零，则为真 Shell还提供了与( -a )、或( -o )、非( ! )三个逻辑操作符用于将测试条件连接起来，其优先级为：&quot;!&quot;最高，&quot;-a&quot;次之，&quot;-o&quot;最低。 test用法 文件测试 cd /bin if test -e ./bash then echo '文件已存在!' else echo '文件不存在!' fi 输出结果 文件已存在! 数值测试 num1=100 num2=100 if test $[num1] -eq $[num2] then echo '两个数相等！' else echo '两个数不相等！' fi 输出结果 两个数相等！ 字符串测试 num1=&quot;ru1noob&quot; num2=&quot;runoob&quot; if test $num1 = $num2 then echo '两个字符串相等!' else echo '两个字符串不相等!' fi 输出结果 两个字符串不相等! xarge ","link":"https://mzqk.github.io/post/linux-chang-yong-ming-ling/"},{"title":"Oracle Sysdate 时间函数","content":"Oracle 时间函数 天粒度 SELECT TRUNC(sysdate,'DD') FROM dual; sysdate+1 加一天 小时粒度 取10天前0点 SELECT TRUNC(sysdate-10,'DD') FROM dual; 取3小时前 SELECT TRUNC(sysdate-3/24,'HH') FROM dual; select sysdate - 3/24 from taa_onerow sysdate+1/24 加1小时 分钟粒度 sysdate+1/(2460) 加1分钟 sysdate+1/(2460*60) 加1秒钟 类推至毫秒0.001秒 函数运算 加法 select sysdate,add_months(sysdate,12) from dual; --加1年 select sysdate,add_months(sysdate,1) from dual; --加1月 select sysdate,to_char(sysdate+7,'yyyy-mm-dd HH24:MI:SS') from dual; --加1星期 select sysdate,to_char(sysdate+1,'yyyy-mm-dd HH24:MI:SS') from dual; --加1天 select sysdate,to_char(sysdate+1/24,'yyyy-mm-dd HH24:MI:SS') from dual; --加1小时 select sysdate,to_char(sysdate+1/24/60,'yyyy-mm-dd HH24:MI:SS') from dual; --加1分钟 select sysdate,to_char(sysdate+1/24/60/60,'yyyy-mm-dd HH24:MI:SS') from dual; --加1秒 减法 select sysdate,add_months(sysdate,-12) from dual; --减1年 select sysdate,add_months(sysdate,-1) from dual; --减1月 select sysdate,to_char(sysdate-7,'yyyy-mm-dd HH24:MI:SS') from dual; --减1星期 select sysdate,to_char(sysdate-1,'yyyy-mm-dd HH24:MI:SS') from dual; --减1天 select sysdate,to_char(sysdate-1/24,'yyyy-mm-dd HH24:MI:SS') from dual; --减1小时 select sysdate,to_char(sysdate-1/24/60,'yyyy-mm-dd HH24:MI:SS') from dual; --减1分钟 select sysdate,to_char(sysdate-1/24/60/60,'yyyy-mm-dd HH24:MI:SS') from dual; --减1秒 ","link":"https://mzqk.github.io/post/oracle-sysdate-shi-jian-han-shu/"},{"title":"安装 Hadoop","content":"安装java环境 安装jdk 设置java环境变量 vim /etc/profile export JAVA_HOME=/usr/lib/jvm/java-7-openjdk-amd64/ eport JRE_HOME=$JAVA_HOME/jre eport CLASSPATH=$JAVA_HOME/lib:$JRE_HOME:lib:$CLASPATH export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 下载hadoop源码包 配置文件在hadoop目录下conf hadoop-env.sh mapred-site.xml core-site.xml hadfs-site.xml 设置hadoop环境变量 格式化操作 hadoop namenode - fromat jps查看hadoop运行进程 hadoop基础命令 hadoop fs -ls / hadoop fs -mkdir filename hadoop fs -put file filename/ hadoop fs -cat filename/file hadoop fs -get filename/file newfile hadoop dfsadmin -report #查看hadoop文件信息 hive安装 下载hive安装包 hive目录lib导入mysql.jar包 配置文件在hive目录下conf hive-env.sh hive-site.xml mysql连接url地址 mysql驱动名字 用户名 密码 hive CLI模式 ","link":"https://mzqk.github.io/post/an-zhuang-hadoop/"},{"title":"Markdown 基础使用","content":"目录 [TOC] 标题 一级标题 二级标题 三级标题 四级标题 五级标题 无序列表 1 2 3 有序列表 1 2 3 引用 这里是引用 图片 链接 百度 粗体 这是粗体 斜体 这是斜体 表格 Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 代码框 #include&lt;stdio.h&gt; int mian() { printf(&quot;Hello world !\\n&quot;); return 0; } 分割线 代办列表 1 2 流程图 graph LR A--&gt;B 时序图 sequenceDiagram A-&gt;&gt;B: How are you? B-&gt;&gt;A: Great! 甘特图 gantt dateFormat YYYY-MM-DD section S1 T1: 2014-01-01, 9d section S2 T2: 2014-01-11, 9d section S3 T3: 2014-01-02, 9d ","link":"https://mzqk.github.io/post/markdown-ji-chu-shi-yong/"},{"title":"Vim 基础使用","content":"一般模式 h j k l ← ↓ ↑ → 命令 说明 w 下一个单词 b 上一个单词 0 行首 $ 行末 G 最后一行 gg,1G 最上一行 ctrl+f 向下翻页 ctrl+b 向上翻页 n 后移n个字符 操作 解释 /word 向下查找 ?word 向上查找 dd 删除一行 yy 复制一行 p,P 粘贴 u 还原 j 合并下一行 块选择 命令 说明 v 字符选择 V 列选择 ctrl+v 快选择 编辑模式 命令 说明 i 在当前光标插入 I 在行首插入 A 在行末加入 a 在光标后插入 o 添加至下一行 O 添加至上一行 命令模式 命令 说明 wq 保存退出 r[filename] 添加文件内容 w[filename] 另存为 !command 命令行 s/word1/word2/g 替换内容 多文件编辑 多窗口模式 命令 说明 :sp filename 在新窗口打开文件 crtl+w+j 向下编辑窗口文件 crtl+w+k 向上编辑窗口文件 crtl+w+k 结束窗口文件 ","link":"https://mzqk.github.io/post/vim-ji-chu-shi-yong/"},{"title":"使用 Linux 远程连接 Windows","content":"办公环境为windows server2003与server2008 确保连接公司专线（或则挂载公司VPN）++修改IPv4的ip地址与网关掩码++ 查看本机网卡配置 ifconfig 添加路由 route add -net 10.175.0.0 netmask 255.255.0.0 gw 10.175.24.254 dev eth0 修改网关 route add -vF 10.175.0.0 netmask 255.255.0.0 gw 10.175.24.254 dev eth0 linux使用的软件为 remmina freerdp ","link":"https://mzqk.github.io/post/shi-yong-linux-yuan-cheng-lian-jie-windows/"},{"title":"Linux管理用户","content":"添加用户名 useradd -m name 创建用户指定家目录 useradd -d /home/name -m name 修改用户家目录 usermod -d /home/newname name 允许用户使用SSH登入 vim /etc/ssh/sshd_config AllowUsers name 修改用户默认shell 1.useradd --shell /usr/bin/zsh name 2.vim /etc/passwd name.....：/usr/bin/zsh 给予用户root权限 1.usermod -aG sudo name 2.vim /etc/sudoers name ALL(ALL:ALL) ALL ","link":"https://mzqk.github.io/post/linux-guan-li-yong-hu/"},{"title":"我的 Bash 配置","content":"# ~/.bashrc: executed by bash(1) for non-login shells. # see /usr/share/doc/bash/examples/startup-files (in the package bash-doc) # for examples # If not running interactively, don't do anything case $- in *i*) ;; *) return;; esac # don't put duplicate lines or lines starting with space in the history. # See bash(1) for more options HISTCONTROL=ignoreboth # append to the history file, don't overwrite it shopt -s histappend # for setting history length see HISTSIZE and HISTFILESIZE in bash(1) HISTSIZE=1000 HISTFILESIZE=2000 # check the window size after each command and, if necessary, # update the values of LINES and COLUMNS. shopt -s checkwinsize # If set, the pattern &quot;**&quot; used in a pathname expansion context will # match all files and zero or more directories and subdirectories. #shopt -s globstar # make less more friendly for non-text input files, see lesspipe(1) [ -x /usr/bin/lesspipe ] &amp;&amp; eval &quot;$(SHELL=/bin/sh lesspipe)&quot; # set variable identifying the chroot you work in (used in the prompt below) if [ -z &quot;${debian_chroot:-}&quot; ] &amp;&amp; [ -r /etc/debian_chroot ]; then debian_chroot=$(cat /etc/debian_chroot) fi # set a fancy prompt (non-color, unless we know we &quot;want&quot; color) case &quot;$TERM&quot; in xterm-color|*-256color) color_prompt=yes;; esac # uncomment for a colored prompt, if the terminal has the capability; turned # off by default to not distract the user: the focus in a terminal window # should be on the output of commands, not on the prompt #force_color_prompt=yes if [ -n &quot;$force_color_prompt&quot; ]; then if [ -x /usr/bin/tput ] &amp;&amp; tput setaf 1 &gt;&amp;/dev/null; then # We have color support; assume it's compliant with Ecma-48 # (ISO/IEC-6429). (Lack of such support is extremely rare, and such # a case would tend to support setf rather than setaf.) color_prompt=yes else color_prompt= fi fi if [ &quot;$color_prompt&quot; = yes ]; then PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ ' else PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ ' fi unset color_prompt force_color_prompt # If this is an xterm set the title to user@host:dir case &quot;$TERM&quot; in xterm*|rxvt*) PS1=&quot;\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1&quot; ;; *) ;; esac # enable color support of ls and also add handy aliases if [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors &amp;&amp; eval &quot;$(dircolors -b ~/.dircolors)&quot; || eval &quot;$(dircolors -b)&quot; alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto' fi # colored GCC warnings and errors #export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01' # some more ls aliases alias ll='ls -alF' alias la='ls -A' alias l='ls -CF' alias rm='rm -i' # Add an &quot;alert&quot; alias for long running commands. Use like so: # sleep 10; alert alias alert='notify-send --urgency=low -i &quot;$([ $? = 0 ] &amp;&amp; echo terminal || echo error)&quot; &quot;$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&amp;|]\\s*alert$//'\\'')&quot;' # Alias definitions. # You may want to put all your additions into a separate file like # ~/.bash_aliases, instead of adding them here directly. # See /usr/share/doc/bash-doc/examples in the bash-doc package. if [ -f ~/.bash_aliases ]; then . ~/.bash_aliases fi # enable programmable completion features (you don't need to enable # this, if it's already enabled in /etc/bash.bashrc and /etc/profile # sources /etc/bash.bashrc). if ! shopt -oq posix; then if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fi fi ","link":"https://mzqk.github.io/post/wo-de-bash-pei-zhi/"},{"title":"安装 LAMP","content":"安装LAMP服务 Linux Apache 安装apache 服务器ip查看运行状态 Mysql 安装mysql 查看php操作模块 /etc/php7/conf.d/mysql.ini 添加php操作模块 php7.0-mysql PHP 安装php 查看php加载模块 /etc/apache2/mods-enabled/php7.load /usr/lib/apache2/modules/libphp7.so 服务器phpinfo探针 /var/www/info.php &lt;?php echo mysql_connect('localhost','root','123456') ? '连接成功' ： '连接失败'； phpinfo(); php扩展 php7.0-gd curl libcurl3 libcurl3-dev php7.0-curl LAMP配置文件 L：/etc A：/etc/apache2 apache.conf 1.conf.d/* 2.httpd.conf 3.mods-enabled/* 4.sites-enabled/* -mods* Apache模块 -sites* 虚拟主机 M:/etc/mysql 核心配置文件my.cnf P:/etc/php7.0 核心配置文件php.ini ","link":"https://mzqk.github.io/post/an-zhuang-lamp/"},{"title":"Hadoop 常见问题","content":"常见问题及处理 mysql版本，必须是MYSQL5.1。 查询办法mysqladmin version 在建立hive数据库的时候，最好是:create database hive; oozie的数据库，同样：create database oozie; hadoop采集的字符集问题。 修改/etc/sysconfig/i18n 更改字符集为en_US.UTF-8 重启机器生效。 重启机器的指令为：在root下敲入如下指令：sync;sync;init 6 修改mapreduce。 在gateway/性能下修改：MapReduce 子 Java 基础选项 、Map 任务 Java 选项库 、Reduce 任务 Java 选项库 全部配置成 -Xmx4294967296 在TASKTRACKER/性能下修改:MapReduce 子 Java 基础选项 、Map 任务 Java 选项库 、Reduce 任务 Java 选项库 全部配置成 -Xmx4294967296 必须关注各个任务的详细情况 当出现如下的错误的时候，请及时的将下载的进程数调小。 vi /home/boco/oozie_wy/config/lte/mro/ftp/807101.xml 将max_thread由原来的6个调整为3个,或者协调厂家加大FTP的最大线程数。 stderr logs： org.apache.commons.net.ftp.FTPConnectionClosedException: FTP response 421 received. Server closed connection. at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:363) at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:290) at org.apache.commons.net.ftp.FTP.connectAction(FTP.java:396) at org.apache.commons.net.ftp.FTPClient.connectAction(FTPClient.java:796) at org.apache.commons.net.SocketClient.connect(SocketClient.java:172) at org.apache.commons.net.SocketClient.connect(SocketClient.java:192) at org.apache.commons.net.SocketClient.connect(SocketClient.java:285) at com.boco.wangyou.utils.Ftp.connectServer(Ftp.java:550) at com.boco.wangyou.lte.mro.ftp.tools.FindFileThread.run(FindFileThread.java:67) 登录ftp服务器【10.140.177.149】失败，FTP服务器无法打开！ org.apache.commons.net.ftp.FTPConnectionClosedException: FTP response 421 received. Server closed connection. at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:363) at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:290) at org.apache.commons.net.ftp.FTP.connectAction(FTP.java:396) at org.apache.commons.net.ftp.FTPClient.connectAction(FTPClient.java:796) at org.apache.commons.net.SocketClient.connect(SocketClient.java:172) at org.apache.commons.net.SocketClient.connect(SocketClient.java:192) at org.apache.commons.net.SocketClient.connect(SocketClient.java:285) at com.boco.wangyou.utils.Ftp.connectServer(Ftp.java:550) at com.boco.wangyou.lte.mro.ftp.tools.FindFileThread.run(FindFileThread.java:67) 登录ftp服务器【10.140.177.149】失败，FTP服务器无法打开！ org.apache.commons.net.ftp.FTPConnectionClosedException: FTP response 421 received. Server closed connection. at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:363) at org.apache.commons.net.ftp.FTP.__getReply(FTP.java:290) at org.apache.commons.net.ftp.FTP.connectAction(FTP.java:396) at org.apache.commons.net.ftp.FTPClient.connectAction(FTPClient.java:796) at org.apache.commons.net.SocketClient.connect(SocketClient.java:172) at org.apache.commons.net.SocketClient.connect(SocketClient.java:192) TASKTRACKER和HDFS组的问题 发现部分地方在安装的时候，将所有的机器分组的问题。 如果分组，需要将每个组的参数都要修改。 目前发现很多的地方，TASKTRACKER和HDFS都分了组，但是只修改一组的参数，造成系统大量出问题。 java heap size以及tasktracker被拉黑名单的问题。 namenode和datanode的内存配置问题。 建议将使用的内存修改为4G左右。 建议将HIVE2服务放到一个辅节点上。 hive2放到辅节点上，经常出现add_partation挂起报错。 解决HIVE经常挂死的问题 修改zookeeper的最大客户端连接数，maxClientCnxns修改为3600或者修改成0不限制 自动清空时间间隔，autopurge.purgeInterval 修改为1小时 厂家XML配置的问题。 如果厂家是这样的：/data/dataservice/mr/ltemro/huawei/20140815/01/362323/TD-LTE_MRO_HUAWEI_010133150144_362323_20140815011500.xml.gz 建议配置成这样的： 路径：/data/dataservice/mr/ltemro/huawei/TIMETIMETIME/ENODEBENODEBENODEB 时间格式：yymmdd/hh 在/home/boco/oozie_wy/config/lte/mro/ftp下禁止存放.bak文件 有一个省份的mapper数超多，导致解析很长时间没有完成。 进一步发现FTP在合并文件的时候报错，再进一步发现同一个IP地址，同一个OMC启动了三个mapper进程去下载数据导致文件合并失败。 发现是修改了ftp.xml文件，没有删除原来的文件，而是以一个bak文件存放。 删除这些bak文件，mapper数量正常。 原mapper数1731个，删除之后mapper数41个,采集正常。 打开50030看FTP的日志，存在如下的报错： java.io.FileNotFoundException: File does not exist: /user/boco/cache/wy/ltemro/1411032293348/xml/155/2014-09-18_11/TD-LTE_MRO_ERICSSON_OMC1_303024_20140918111500.xml.zip at org.apache.hadoop.hdfs.server.namenode.INodeFile.valueOf(INodeFile.java:39) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsUpdateTimes(FSNamesystem.java:1341) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocationsInt(FSNamesystem.java:1293) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1269) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getBlockLocations(FSNamesystem.java:1242) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getBlockLocations(NameNodeRpcServer.java:392) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getBlockLocations(ClientNamenodeProtocolServerSideTranslatorPB.java:172) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44938)atorg.apache.hadoop.ipc.ProtobufRpcEngine2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44938) at org.apache.hadoop.ipc.ProtobufRpcEngine2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44938)atorg.apache.hadoop.ipc.ProtobufRpcEngineServerProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453)atorg.apache.hadoop.ipc.RPCProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453) at org.apache.hadoop.ipc.RPCProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453)atorg.apache.hadoop.ipc.RPCServer.call(RPC.java:1002) at org.apache.hadoop.ipc.Server$Handler1.run(Server.java:1701)atorg.apache.hadoop.ipc.Server1.run(Server.java:1701) at org.apache.hadoop.ipc.Server1.run(Server.java:1701)atorg.apache.hadoop.ipc.ServerHandler1.run(Server.java:1697)atjava.security.AccessController.doPrivileged(NativeMethod)或者：org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException):Leasemismatchon/user/boco/cache/wy/ltemro/1411032293348/xml/155/2014−09−1811/TD−LTEMROERICSSONOMC1303020140918.xmlownedbyDFSClientNONMAPREDUCE−12748272121butisaccessedbyDFSClientNONMAPREDUCE−2166139051atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2459)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2437)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2503)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2480)atorg.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:535)atorg.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:337)atorg.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos1.run(Server.java:1697) at java.security.AccessController.doPrivileged(Native Method) 或者： org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException): Lease mismatch on /user/boco/cache/wy/ltemro/1411032293348/xml/155/2014-09-18_11/TD-LTE_MRO_ERICSSON_OMC1_3030_20140918.xml owned by DFSClient_NONMAPREDUCE_-1274827212_1 but is accessed by DFSClient_NONMAPREDUCE_-216613905_1 at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2459) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2437) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2503) at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2480) at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:535) at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:337) at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos1.run(Server.java:1697)atjava.security.AccessController.doPrivileged(NativeMethod)或者：org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.LeaseExpiredException):Leasemismatchon/user/boco/cache/wy/ltemro/1411032293348/xml/155/2014−09−181​1/TD−LTEM​ROE​RICSSONO​MC13​0302​0140918.xmlownedbyDFSClientN​ONMAPREDUCE−​12748272121​butisaccessedbyDFSClientN​ONMAPREDUCE−​2166139051​atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2459)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkLease(FSNamesystem.java:2437)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFileInternal(FSNamesystem.java:2503)atorg.apache.hadoop.hdfs.server.namenode.FSNamesystem.completeFile(FSNamesystem.java:2480)atorg.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.complete(NameNodeRpcServer.java:535)atorg.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.complete(ClientNamenodeProtocolServerSideTranslatorPB.java:337)atorg.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtosClientNamenodeProtocol2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44958)atorg.apache.hadoop.ipc.ProtobufRpcEngine2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44958) at org.apache.hadoop.ipc.ProtobufRpcEngine2.callBlockingMethod(ClientNamenodeProtocolProtos.java:44958)atorg.apache.hadoop.ipc.ProtobufRpcEngineServerProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453)atorg.apache.hadoop.ipc.RPCProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453) at org.apache.hadoop.ipc.RPCProtoBufRpcInvoker.call(ProtobufRpcEngine.java:453)atorg.apache.hadoop.ipc.RPCServer.call(RPC.java:1002) REDIS故障 解析时候报错，错误如下： redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool at redis.clients.util.Pool.getResource(Pool.java:22) at com.boco.wangyou.utils.JedisUtils.getJedis(JedisUtils.java:47) at com.boco.wangyou.utils.JedisUtils.getTableValues(JedisUtils.java:119) at com.boco.wangyou.lte.mro.tdl.tools.LteMroXMLParser.(LteMroXMLParser.java:82) at com.boco.wangyou.lte.mro.tdl.XMLParseMapper.map(XMLParseMapper.java:44) at com.boco.wangyou.lte.mro.tdl.XMLParseMapper.map(XMLParseMapper.java:18) at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:140) 此问题一般是因为REDIS没有启动导致。 克隆机器安装的问题 把一个节点的第二步都装好了，把它克隆到其它主机上，再把克隆到的主机的IP （注意在修改IP配置文件的时候，将HWaddr也改了，一般是这种格式：00:50:56:80:4E:D6， 否则在连接时会找不到硬盘）和主机名改下。 此种情况主要出现在使用vmvare vsphere克隆导致的。 注意： 克隆之后的机器要修改IP地址，主机名，MAC地址。 redis挂死，导致无法采集 #现象 #redis.clients.jedis.exceptions.JedisDataException: MISCONF Redis is configured to save RDB snapshots, but is currently not able to persist on disk. #启动客户端： /usr/local/redis/redis-cli #输入： config set stop-writes-on-bgsave-error no 主节点7180无法访问 1）检查主节点是不是日志空间满了，如果满了，需要删除/var/log/hive下面日志 2）删除浏览器的cookie访问记录 hadoop相关服务启动命令： sudo service cloudera-scm-server stop sudo service cloudera-scm-server-db stop sudo service cloudera-scm-server start sudo service cloudera-scm-server-db start LTEMRO采集报错 主要是在这一步报错：CREATE_EXTERNAL_TABLE_NODE 有效的采样点数据，是如下的八个字段必须有值： MR.LteScEarfcn 主小区频点 MR.LteScPci 主小区PCI MR.LteScRSRP 主小区的RSRP MR.LteScRSRQ 主小区RSRQ MR.LteNcEarfcn 邻小区频点 MR.LteNcPci 邻小区PCI MR.LteNcRSRP 邻小区的RSRP MR.LteNcRSRQ 邻小区RSRQ 只要有有效数据，就不会报这个错。 查看日志 HIVE的日志主要是在:/var/log/hive/ oozie的日志主要在: /var/log/oozie/ HDFS的日志主要在: /var/log/hadoop-hdfs/ zookeeper的日志主要在:/var/log/zookeeper/ 在出现问题的时候，可以看看这些日志。 zookeeper无法启动。 报错如下： 处理办法：到master主机的/var/lib/zookeeper，删除所有的文件，重启zookeeper即可。 sudo mkdir version-2 sudo chown -R zookeeper:zookeeper version-2 loudera-manager-installer.bin安装报错。 报错如下： Loaded plugins: aliases, changelog, downloadonly, fastestmirror, kabi, presto, : refresh-packagekit, security, tmprepo, verify, versionlock Loading support for CentOS kernel ABI Loading mirror speeds from cached hostfile http://10.233.9.63/cdh4.3.0/cdh4.3/repodata/repomd.xml: [Errno 14] PYCURL ERROR 22 - &quot;The requested URL returned error: 403&quot; Trying other mirror. Error: Cannot retrieve repository metadata (repomd.xml) for repository: cloudera-cdh4. Please verify its path and try again 处理办法： 删除集群中每一台机器上原有的repo文件，rm -rf /etc/yum.repos.d/* 然后修改cloudera-chd4.repo、cloudera-impala.repo和 cloudera-manager.repo文件，将文件中的地址换成主节点的地址。 将cloudera-chd4.repo、cloudera-impala.repo和 cloudera-manager.repo文件上传到集群中每一台机器的/etc/yum.repos.d/目录下。 ","link":"https://mzqk.github.io/post/hadoop-chang-jian-wen-ti/"}]}